{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yushi/anaconda3/envs/toxicity/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import (\n",
    "    HookedTransformer,\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neuron_metrics = pd.read_csv('./all_neuron_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter top toxic value vectors with initial positive activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked layer_idx and neuron_idx saved to toxic_positive_acts_idxs.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter the DataFrame to include only rows with positive gpt2_activation and being toxic\n",
    "positive_activations = all_neuron_metrics[all_neuron_metrics['gpt2_activation'] > 0]\n",
    "positive_activations = positive_activations[positive_activations['cosine_similarity'] > 0]\n",
    "\n",
    "# Step 2: Rank these rows by cosine similarity in descending order\n",
    "positive_activations['cossim_rank'] = positive_activations['cosine_similarity'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "# Step 3: Sort the DataFrame by the ranks\n",
    "positive_activations_sorted = positive_activations.sort_values('cossim_rank')\n",
    "\n",
    "# Step 4: Select only the layer_idx and neuron_idx columns\n",
    "layer_neuron_ids = positive_activations_sorted[['layer_idx', 'neuron_idx']]\n",
    "\n",
    "# Step 5: Save the result to a CSV file\n",
    "output_file = 'toxic_positive_acts_idxs.csv'\n",
    "layer_neuron_ids.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Ranked layer_idx and neuron_idx saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5770\n"
     ]
    }
   ],
   "source": [
    "print(len(layer_neuron_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter top toxic value vectors with their initial key vector and bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n",
      "       layer_idx  neuron_idx  \\\n",
      "78594         19         770   \n",
      "49923         12         771   \n",
      "76397         18        2669   \n",
      "53916         13         668   \n",
      "65791         16         255   \n",
      "\n",
      "                                              key_vector  bias_term  \n",
      "78594  [-0.024163583293557167, -0.017355741932988167,...  -0.226177  \n",
      "49923  [-0.010582792572677135, 0.0035662075970321894,...  -0.694075  \n",
      "76397  [-0.03616376593708992, 0.03283524513244629, -0...  -0.291046  \n",
      "53916  [-0.006538663990795612, 0.019593868404626846, ...  -0.465313  \n",
      "65791  [-0.030100855976343155, 0.055411819368600845, ...  -0.162906  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "all_neuron_metrics = pd.read_csv('./all_neuron_metrics.csv')\n",
    "\n",
    "# Step 1: Rank all rows based on cosine similarity (descending order)\n",
    "all_neuron_metrics['cossim_rank'] = all_neuron_metrics['cosine_similarity'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "# Step 2: Sort the DataFrame by the cossim_rank\n",
    "ranked_df = all_neuron_metrics.sort_values('cossim_rank')[['layer_idx', 'neuron_idx']]\n",
    "\n",
    "# Initialize the model\n",
    "torch.set_grad_enabled(False)\n",
    "gpt2 = HookedTransformer.from_pretrained(\"gpt2-medium\")\n",
    "gpt2.tokenizer.padding_side = \"left\"\n",
    "gpt2.tokenizer.pad_token_id = gpt2.tokenizer.eos_token_id\n",
    "\n",
    "# Step 3: Add columns for key vectors and bias terms\n",
    "key_vectors = []\n",
    "bias_terms = []\n",
    "\n",
    "for _, row in ranked_df.iterrows():\n",
    "    layer_idx = int(row['layer_idx'])  # Convert layer_idx to an integer\n",
    "    neuron_idx = int(row['neuron_idx'])  # Convert neuron_idx to an integer\n",
    "    \n",
    "    # Extract the key vector and bias term\n",
    "    key_vector = gpt2.blocks[layer_idx].mlp.W_in[:, neuron_idx].cpu().numpy().tolist()  # Convert to list\n",
    "    bias = gpt2.blocks[layer_idx].mlp.b_in[neuron_idx].cpu().item()  # Get the bias term as a scalar\n",
    "    \n",
    "    # Store them in the lists\n",
    "    key_vectors.append(key_vector)\n",
    "    bias_terms.append(bias)\n",
    "\n",
    "# Add the lists as new columns in the DataFrame\n",
    "ranked_df['key_vector'] = key_vectors\n",
    "ranked_df['bias_term'] = bias_terms\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(ranked_df.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "ranked_df.to_csv('toxic_neurons_with_key_vectors_and_bias.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxicity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
