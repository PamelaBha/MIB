{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/data/kebl6672/dpo-toxic-general')\n",
    "sys.path.append('/data/kebl6672/dpo-toxic-general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kebl6672/miniconda3/envs/toxic/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Module Doc String\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "from fancy_einsum import einsum\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "# from toxicity.figures.fig_utils import load_hooked\n",
    "# from constants import MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/data/kebl6672/dpo-toxic-general')\n",
    "sys.path.append('/data/kebl6672/dpo-toxic-general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\") \n",
    "ROOT_DIR = \"/data/kebl6672/dpo-toxic-general\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-medium\" # \"mistralai/Mistral-7B-Instruct-v0.1\" #\"google/gemma-2-2b\" # \"gpt2-medium\", \"mistralai/Mistral-7B-Instruct-v0.1\", \"meta-llama/Llama-3.1-8B\", \"google/gemma-2-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logitlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the MLP second weight vector\n",
    "def extract_value_vector(model, layer_idx, neuron_idx):\n",
    "    # Access the MLP's c_proj weights for the specified layer\n",
    "    c_proj_weights = model.blocks[layer_idx].mlp.W_out  # Shape: (d_model, d_mlp)\n",
    "\n",
    "    # Extract the vector for the specified neuron\n",
    "    vector = c_proj_weights[neuron_idx]  # Shape: (d_model,)\n",
    "\n",
    "    return vector\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "layer_idx = 19\n",
    "neuron_idx = 770\n",
    "\n",
    "# Extract the value vector for layer 19, neuron 770\n",
    "most_toxic_value_vector = extract_value_vector(model, layer_idx, neuron_idx)\n",
    "\n",
    "print(\"Extracted vector shape:\", most_toxic_value_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tokens(vector, W_U, tokenizer, top_k=10):\n",
    "    \"\"\"\n",
    "    Projects a feature vector onto the vocabulary space using the model's unembedding matrix\n",
    "    and returns the top-k most similar tokens.\n",
    "    \n",
    "    Args:\n",
    "        vector (torch.Tensor): The probe vector (shape: d_model).\n",
    "        W_U (torch.Tensor): The unembedding layer (vocab_size, d_model).\n",
    "        tokenizer: The model tokenizer.\n",
    "        top_k (int): Number of top tokens to return.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: [(token, probability), ...]\n",
    "    \"\"\"\n",
    "    # Ensure vector shape is (d_model,)\n",
    "    if vector.dim() == 2:\n",
    "        vector = vector.squeeze(0)  # (1, d_model) -> (d_model,)\n",
    "\n",
    "    # Project the vector onto vocab space\n",
    "    vocab_projection = torch.matmul(vector, W_U.T)  # Shape: (vocab_size,)\n",
    "\n",
    "    # Convert to probabilities using softmax\n",
    "    probs = torch.softmax(vocab_projection, dim=-1)\n",
    "\n",
    "    # Get top K token indices and probabilities\n",
    "    top_probs, top_indices = torch.topk(probs, top_k)\n",
    "\n",
    "    # Decode tokens\n",
    "    top_tokens = [tokenizer.decode([idx]) for idx in top_indices]\n",
    "\n",
    "    # Return as a list of tuples (token, probability)\n",
    "    return list(zip(top_tokens, top_probs.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to project a vector to vocab space and get top 10 tokens\n",
    "# def get_top_tokens(vector, W_U, tokenizer, top_k=10):\n",
    "#     # Project the vector onto vocab space\n",
    "#     vocab_projection = torch.matmul(vector, W_U)  # Shape: (d_vocab,)\n",
    "\n",
    "#     # Convert to probabilities using softmax\n",
    "#     probs = torch.softmax(vocab_projection, dim=-1)\n",
    "\n",
    "#     # Get top K token indices and probabilities\n",
    "#     top_probs, top_indices = torch.topk(probs, top_k)\n",
    "\n",
    "#     # Decode tokens\n",
    "#     top_tokens = [tokenizer.decode([idx]) for idx in top_indices]\n",
    "\n",
    "#     # Return as a list of tuples (token, probability)\n",
    "#     return list(zip(top_tokens, top_probs.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the toxicity probe\n",
    "# toxic_probe = torch.load(os.path.join(ROOT_DIR, \"checkpoints/gpt2_probe.pt\")).to(device) \n",
    "toxic_probe = torch.load(os.path.join(ROOT_DIR, \"checkpoints/llama_probe.pt\")).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Tokens Projected from Toxic Probe:\n",
      "Token: ển, Probability: 0.000016479\n",
      "Token: kommen, Probability: 0.000016409\n",
      "Token:  FUCK, Probability: 0.000016168\n",
      "Token: iyah, Probability: 0.000015594\n",
      "Token: 털, Probability: 0.000015316\n",
      "Token: ̆, Probability: 0.000015202\n",
      "Token: fuck, Probability: 0.000015128\n",
      "Token: dirty, Probability: 0.000014995\n",
      "Token: arton, Probability: 0.000014574\n",
      "Token: ToBounds, Probability: 0.000014554\n",
      "Token:  Rudd, Probability: 0.000014531\n",
      "Token: ên, Probability: 0.000014486\n",
      "Token:  порт, Probability: 0.000014437\n",
      "Token: arel, Probability: 0.000014410\n",
      "Token:  Кра, Probability: 0.000014410\n",
      "Token: ….\n",
      "\n",
      ", Probability: 0.000014278\n",
      "Token: gart, Probability: 0.000014239\n",
      "Token: ityEngine, Probability: 0.000014229\n",
      "Token: .Slf, Probability: 0.000014215\n",
      "Token: NetMessage, Probability: 0.000014211\n",
      "Token:  xsi, Probability: 0.000014122\n",
      "Token: ToProps, Probability: 0.000014106\n",
      "Token: ーニ, Probability: 0.000014053\n",
      "Token: kees, Probability: 0.000014033\n",
      "Token: venir, Probability: 0.000014000\n",
      "Token: chrift, Probability: 0.000013925\n",
      "Token: OLEAN, Probability: 0.000013923\n",
      "Token:  Đông, Probability: 0.000013921\n",
      "Token: 레벨, Probability: 0.000013898\n",
      "Token: tier, Probability: 0.000013859\n"
     ]
    }
   ],
   "source": [
    "# Get top 10 tokens of the toxic probe\n",
    "top_10_tokens = get_top_tokens(toxic_probe, model.lm_head.weight, tokenizer, top_k=30)\n",
    "\n",
    "# Print results\n",
    "print(\"Top 10 Tokens Projected from Toxic Probe:\")\n",
    "for token, prob in top_10_tokens:\n",
    "    print(f\"Token: {token}, Probability: {prob:.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the toxicity probe\n",
    "toxic_probe = torch.load(os.path.join(ROOT_DIR, \"checkpoints/gpt2_probe.pt\")).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Tokens Projected from Toxic Probe:\n",
      "Token: Fuck, Probability: 0.156536207\n",
      "Token:  FUCK, Probability: 0.107314922\n",
      "Token: fuck, Probability: 0.058655694\n",
      "Token:  Fuck, Probability: 0.047995940\n",
      "Token:  fucking, Probability: 0.046780676\n",
      "Token:  cunt, Probability: 0.022722524\n",
      "Token:  fuck, Probability: 0.021766283\n",
      "Token:  Shit, Probability: 0.021676421\n",
      "Token: shit, Probability: 0.016469916\n",
      "Token:  goddamn, Probability: 0.013456282\n",
      "Token:  asshole, Probability: 0.013199502\n",
      "Token:  fucked, Probability: 0.012850781\n",
      "Token:  Godd, Probability: 0.009093617\n",
      "Token:  whore, Probability: 0.007361848\n",
      "Token:  godd, Probability: 0.005862250\n",
      "Token:  fuckin, Probability: 0.003880905\n",
      "Token:  shit, Probability: 0.003843054\n",
      "Token:  worthless, Probability: 0.003734149\n",
      "Token:  bitch, Probability: 0.003228735\n",
      "Token:  retarded, Probability: 0.002757493\n"
     ]
    }
   ],
   "source": [
    "# Get top 10 tokens of the toxic probe\n",
    "top_10_tokens = get_top_tokens(toxic_probe, model.lm_head.weight, tokenizer, top_k=20)\n",
    "\n",
    "# Print results\n",
    "print(\"Top 10 Tokens Projected from Toxic Probe:\")\n",
    "for token, prob in top_10_tokens:\n",
    "    print(f\"Token: {token}, Probability: {prob:.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the toxicity probe\n",
    "# toxic_probe = torch.load(os.path.join(ROOT_DIR, \"checkpoints/gpt2_probe.pt\")).to(device) \n",
    "toxic_probe = torch.load(os.path.join(ROOT_DIR, \"checkpoints/mistral_probe.pt\")).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Tokens Projected from Toxic Probe:\n",
      "Token: shit, Probability: 0.000034220\n",
      "Token: shit, Probability: 0.000034109\n",
      "Token: fuck, Probability: 0.000033883\n",
      "Token: Fuck, Probability: 0.000033876\n",
      "Token: fucking, Probability: 0.000033648\n",
      "Token: assh, Probability: 0.000033392\n",
      "Token: bullshit, Probability: 0.000033335\n",
      "Token: fucked, Probability: 0.000033323\n",
      "Token: asshole, Probability: 0.000033312\n",
      "Token: upid, Probability: 0.000033289\n",
      "Token: dick, Probability: 0.000033108\n",
      "Token: shitty, Probability: 0.000033086\n",
      "Token: biologie, Probability: 0.000033049\n",
      "Token: idiot, Probability: 0.000033038\n",
      "Token: irtual, Probability: 0.000033001\n",
      "Token: crap, Probability: 0.000032951\n",
      "Token: bast, Probability: 0.000032911\n",
      "Token: cí, Probability: 0.000032899\n",
      "Token: Checked, Probability: 0.000032885\n",
      "Token: ﬁ, Probability: 0.000032863\n"
     ]
    }
   ],
   "source": [
    "# Get top 10 tokens of the toxic probe\n",
    "top_10_tokens = get_top_tokens(toxic_probe, model.lm_head.weight, tokenizer, top_k=20)\n",
    "\n",
    "# Print results\n",
    "print(\"Top 10 Tokens Projected from Toxic Probe:\")\n",
    "for token, prob in top_10_tokens:\n",
    "    print(f\"Token: {token}, Probability: {prob:.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 tokens of the toxic probe\n",
    "top_10_tokens = get_top_tokens(toxic_probe, model.lm_head.weight, tokenizer, top_k=20)\n",
    "\n",
    "# Print results\n",
    "print(\"Top 10 Tokens Projected from Toxic Probe:\")\n",
    "for token, prob in top_10_tokens:\n",
    "    print(f\"Token: {token}, Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 tokens of the toxic probe\n",
    "top_10_tokens = get_top_tokens(toxic_probe, model.lm_head.weight, tokenizer, top_k=20)\n",
    "\n",
    "# Print results\n",
    "print(\"Top 10 Tokens Projected from Toxic Probe:\")\n",
    "for token, prob in top_10_tokens:\n",
    "    print(f\"Token: {token}, Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 tokens of the most toxic value vector\n",
    "top_10_tokens = get_top_tokens(most_toxic_value_vector, model.W_U, model.tokenizer, top_k=10)\n",
    "\n",
    "# Print results\n",
    "for token, prob in top_10_tokens:\n",
    "    print(f\"Token: {token}, Probability: {prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('./all_neuron_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kth_row_layer_neuron_index(df, k):\n",
    "    # Sort the DataFrame by cosine similarity in descending order\n",
    "    sorted_df = df.sort_values(by='cosine_similarity', ascending=False)\n",
    "\n",
    "    # Get the k-th row (convert k to 0-based index)\n",
    "    kth_row = sorted_df.iloc[k - 1]\n",
    "\n",
    "    return int(kth_row['layer_idx']), int(kth_row['neuron_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "k = 129 # Specify the k value (1-based index)\n",
    "layer_idx, neuron_idx = get_kth_row_layer_neuron_index(df, k)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Layer Index: {layer_idx}, Neuron Index: {neuron_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "k = 128  # Specify the k value (the cosine similarity rank index)\n",
    "layer_idx, neuron_idx = get_kth_row_layer_neuron_index(df, k)\n",
    "\n",
    "# Extract the corresponding value vector\n",
    "value_vector = extract_value_vector(model, layer_idx, neuron_idx)\n",
    "\n",
    "# Get top 10 tokens of the value vector\n",
    "top_10_tokens = get_top_tokens(value_vector, model.W_U, model.tokenizer, top_k=10)\n",
    "\n",
    "# Print results\n",
    "for token, prob in top_10_tokens:\n",
    "    print(f\"Token: {token}, Probability: {prob}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
