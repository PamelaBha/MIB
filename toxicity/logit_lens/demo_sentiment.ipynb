{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b72fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer\n",
    "from fancy_einsum import einsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c884a7",
   "metadata": {},
   "source": [
    "#### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36bdecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-medium\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bb7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([98304, 1024])\n"
     ]
    }
   ],
   "source": [
    "token_embeds = model.transformer.wte.weight\n",
    "value_vectors = torch.cat(\n",
    "    [\n",
    "        model.transformer.h[layer_idx].mlp.c_proj.weight\n",
    "        for layer_idx in range(model.config.num_hidden_layers)\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "print(value_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0c18e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34191, 2633, 3772, 8716, 8212]\n",
      "[6507, 7954, 16234]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed_token_pos = [\"happy\", \"joy\", \" happy\", \" joy\", \" smile\"]\n",
    "seed_token_neg = [\" sad\", \" angry\", \" disgust\"]\n",
    "\n",
    "pos_token_id = [tokenizer.encode(tok)[0] for tok in seed_token_pos]\n",
    "neg_token_id = [tokenizer.encode(tok)[0] for tok in seed_token_neg]\n",
    "\n",
    "print(pos_token_id)\n",
    "print(neg_token_id)\n",
    "\n",
    "pos_embed = token_embeds[pos_token_id].mean(dim=0)\n",
    "neg_embed = token_embeds[neg_token_id].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d66cf1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unembed_to_text(vector, model, tokenizer, k=10):\n",
    "    norm = model.transformer.ln_f\n",
    "    lm_head = model.lm_head.weight\n",
    "    dots = einsum(\"vocab d_model, d_model -> vocab\", lm_head, norm(vector))\n",
    "    top_k = dots.topk(k).indices\n",
    "    return tokenizer.batch_decode(top_k, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f336d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 80, index 988\n",
      "[' secure', ' successful', ' successfully', ' satisfactory', ' optimal', ' improved', ' optim', ' perfected', ' excellent', ' efficient']\n",
      "Value vec: Layer 67, index 136\n",
      "[' peaceful', ' stable', ' satisfactory', ' good', ' trustworthy', ' safe', ' reassured', ' credibility', 'Safe', ' impartial']\n",
      "Value vec: Layer 54, index 386\n",
      "[' positives', ' advant', ' blessed', ' mirac', ' upl', ' pristine', ' bright', ' smiles', ' buoy', ' boon']\n",
      "Value vec: Layer 71, index 367\n",
      "[' Congratulations', 'osponsors', 'Congratulations', ' Honor', 'aug', ' enriched', ' Excellence', ' rewarded', ' Blossom', ' Celebr']\n",
      "Value vec: Layer 60, index 301\n",
      "[' collaborations', ' achievements', ' excellence', ' breakthrough', ' Inspired', ' Excellence', ' inspired', ' Aub', ' amazing', ' Citation']\n",
      "Value vec: Layer 93, index 414\n",
      "['hari', ' externalToEVAOnly', 'perm', 'ifty', 'kin', ' Atomic', 'ourced', 'pac', '=-=-=-=-=-=-=-=-', 'allows']\n",
      "Value vec: Layer 54, index 440\n",
      "[' unaffected', ' antioxid', 'but', ' flourishing', ' but', ' plent', ' reassuring', ' intact', ' plentiful', 'However']\n",
      "Value vec: Layer 67, index 701\n",
      "[' enjoying', ' joy', ' exhilar', ' enjoyed', ' enjoyment', ' pleasures', ' delight', ' enjoy', ' glorious', ' enjoys']\n",
      "Value vec: Layer 71, index 123\n",
      "[' productive', ' victories', ' success', ' favourable', ' brill', ' satisfactory', ' clarity', ' successes', ' positive', ' reassuring']\n",
      "Value vec: Layer 59, index 233\n",
      "[' sanct', ' dign', ' dignity', ' vitality', 'tesy', ' honour', 'Faith', ' colleg', 'Merit', ' prosper']\n",
      "Value vec: Layer 54, index 565\n",
      "[' compliment', ' amazing', ' insights', ' inspiring', ' unparalleled', ' unmatched', ' innovative', ' synergy', ' compliments', ' awesome']\n",
      "Value vec: Layer 65, index 13\n",
      "[' benefits', 'benef', ' complimentary', ' benefit', ' generous', ' rehabilitation', 'benefit', ' Benefits', ' improvements', ' rehabilit']\n",
      "Value vec: Layer 68, index 397\n",
      "[' entr', ' Dian', ' attraction', ' congr', 'larg', ' stimulation', ' Peng', 'angelo', ' collaborations', ' Celebr']\n",
      "Value vec: Layer 64, index 755\n",
      "[' Blessing', 'ellation', 'isSpecialOrderable', ' Bless', 'eness', '++++++++++++++++', ' Elev', 'ogle', 'eral', 'ede']\n",
      "Value vec: Layer 66, index 814\n",
      "[' satisf', ' positively', ' trustworthy', ' favorably', ' prosper', ' Airl', ' praise', ' praises', ' promot', ' trust']\n",
      "Value vec: Layer 64, index 151\n",
      "[' smoothly', ' seamlessly', ' effortlessly', ' seamless', ' confidently', 'esty', ' smooth', ' trustworthy', ' safely', ' securely']\n",
      "Value vec: Layer 64, index 588\n",
      "[' innocent', ' Palestin', ' civilians', ' democracy', ' welf', ' peaceful', ' nonviolent', ' moms', ' democratic', ' innoc']\n",
      "Value vec: Layer 57, index 25\n",
      "[' rejuven', ' improved', ' restored', 'Benef', ' prosper', 'tesy', ' opportunities', ' boon', ' enjoying', ' mirac']\n",
      "Value vec: Layer 69, index 1009\n",
      "['Austral', 'confidence', 'onomy', 'accompan', 'strength', 'Joy', 'YD', ' LEVEL', ' encouragement', ' maximizing']\n",
      "Value vec: Layer 52, index 670\n",
      "[' hoped', ' semblance', 'ensible', ' hope', ' valiant', ' calmed', ' allev', ' respectable', 'Hope', 'ensibly']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 20\n",
    "norm = model.transformer.ln_f\n",
    "\n",
    "target_vec = pos_embed - neg_embed\n",
    "dot_prods = einsum(\"value_vecs d_model, d_model -> value_vecs\", norm(value_vectors), target_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 1024}, index {vec_idx % 1024}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa2c443",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 70, index 905\n",
      "[' hate', ' hated', ' negativity', ' bad', ' dreaded', ' harmful', ' adversaries', ' enemies', ' harsh', 'enemy']\n",
      "Value vec: Layer 55, index 142\n",
      "[' burdens', ' troubled', ' risks', ' misfortune', ' headache', ' trouble', ' risk', ' nightmare', ' adverse', ' toxicity']\n",
      "Value vec: Layer 69, index 567\n",
      "[' inability', ' failed', ' unable', ' inadequate', ' lack', ' failing', ' lacking', ' failure', ' insufficient', ' fail']\n",
      "Value vec: Layer 68, index 443\n",
      "[' burdens', ' worst', ' worse', ' toxic', ' humiliating', ' waste', ' nightmare', ' pests', ' wasting', ' protracted']\n",
      "Value vec: Layer 64, index 974\n",
      "[' inappropriately', ' prejud', ' unnecessarily', ' improperly', ' unchecked', ' incorrectly', ' inefficient', ' miscon', ' arrogance', ' excessively']\n",
      "Value vec: Layer 81, index 762\n",
      "[' problems', ' malfunction', ' failure', ' failures', ' damage', ' woes', ' dysfunction', ' trouble', ' injuries', ' damaged']\n",
      "Value vec: Layer 65, index 619\n",
      "[' inability', ' ineffective', ' failed', ' insufficient', ' unable', 'failed', ' lose', ' failures', ' lackluster', ' fail']\n",
      "Value vec: Layer 64, index 889\n",
      "[' culprit', ' damaging', ' blamed', ' offending', ' guilty', ' harmful', ' blame', ' damages', ' ruin', ' severe']\n",
      "Value vec: Layer 63, index 287\n",
      "[' jeopard', ' endanger', ' unlawfully', ' tresp', ' violations', ' infring', ' Worse', ' violates', ' damages', 'angering']\n",
      "Value vec: Layer 62, index 139\n",
      "[' inconsistent', ' inconsistency', ' interference', ' incompatible', ' negativity', ' excessive', ' inequ', ' hind', ' misuse', ' mishand']\n",
      "Value vec: Layer 72, index 91\n",
      "[' unintentionally', ' errone', ' confused', ' bizarre', ' mistakenly', ' confusion', ' mis', ' incorrectly', ' mistaken', ' erroneous']\n",
      "Value vec: Layer 55, index 208\n",
      "[' burdens', ' burden', ' difficulty', ' harsh', ' hardships', ' Worst', 'Sad', ' painful', 'stress', ' uncertainties']\n",
      "Value vec: Layer 56, index 220\n",
      "['catentry', ' infringing', ' harmful', ' pitfalls', ' bitterness', ' rash', ' burdens', ' corrupt', 'ンジ', ' negativity']\n",
      "Value vec: Layer 64, index 757\n",
      "[' complications', ' pitfalls', ' risks', ' problems', ' Problems', ' anxiety', ' headaches', 'problem', ' conflicts', ' issues']\n",
      "Value vec: Layer 52, index 690\n",
      "[' hind', ' prejud', ' jeopard', ' Worse', ' infring', ' damaging', ' mishand', ' misrepresent', ' harmful', ' incompatible']\n",
      "Value vec: Layer 63, index 206\n",
      "[' negatives', ' detract', ' disadvantages', ' lows', ' disadvantage', 'Weak', ' downside', ' detrim', ' downfall', ' negative']\n",
      "Value vec: Layer 57, index 696\n",
      "[' harmful', ' damaging', ' nasty', ' malicious', ' disturbing', ' detrimental', ' menace', ' harming', ' destructive', ' nightmares']\n",
      "Value vec: Layer 52, index 1001\n",
      "[' fails', ' fail', ' dimin', ' miss', ' imperfect', ' doubtful', ' failed', ' disappoint', ' unsu', ' missed']\n",
      "Value vec: Layer 83, index 651\n",
      "['etheless', ' scen', ' reconc', ' releg', ' redes', ' merit', ' concern', ' conscientious', ' turbulence', ' precaution']\n",
      "Value vec: Layer 93, index 720\n",
      "[' Nuggets', ' Wasteland', ' SAM', ' Trident', ' wishing', ' payday', ' sleeper', ' Indianapolis', ' independ', ' measures']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_vec = neg_embed - pos_embed\n",
    "\n",
    "dot_prods = einsum(\"value_vecs d_model, d_model -> value_vecs\", norm(value_vectors), target_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 1024}, index {vec_idx % 1024}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6237f0ce",
   "metadata": {},
   "source": [
    "#### Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5801e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6650c05dfea4a3ab7d3e326e4443183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d73017a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([458752, 4096])\n"
     ]
    }
   ],
   "source": [
    "token_embeds = model.model.embed_tokens.weight\n",
    "value_vectors = torch.cat(\n",
    "    [\n",
    "        model.model.layers[layer_idx].mlp.down_proj.weight.T\n",
    "        for layer_idx in range(model.config.num_hidden_layers)\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "print(value_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75bed75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive token IDs: [57621, 4215, 6380, 16267, 15648]\n",
      "Negative token IDs: [12703, 19021, 68162]\n"
     ]
    }
   ],
   "source": [
    "seed_token_pos = [\"happy\", \"joy\", \" happy\", \" joy\", \" smile\"]\n",
    "seed_token_neg = [\" sad\", \" angry\", \" disgust\"]\n",
    "\n",
    "pos_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_pos\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "neg_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_neg\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "print(\"Positive token IDs:\", pos_token_id)\n",
    "print(\"Negative token IDs:\", neg_token_id)\n",
    "\n",
    "pos_embed = token_embeds[pos_token_id].mean(dim=0)\n",
    "neg_embed = token_embeds[neg_token_id].mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be4cea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unembed_to_text(vector, model, tokenizer, k=10):\n",
    "    norm = model.model.norm  \n",
    "    lm_head = model.lm_head.weight\n",
    "\n",
    "    normed_vector = norm(vector.unsqueeze(0)).squeeze(0)  # shape: [d_model]\n",
    "\n",
    "    dots = torch.einsum(\"vd,d->v\", lm_head, normed_vector)\n",
    "\n",
    "    top_k = dots.topk(k).indices\n",
    "    return tokenizer.batch_decode(top_k, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45cfdf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 3, index 1403\n",
      "['ryn', ' Zaman', 'tha', 'rlen', 'lem', ' Major', ' Kaf', 'inventory', 'indexed', ' Lem']\n",
      "Value vec: Layer 1, index 2835\n",
      "[' Karlov', ' Tay', 'osit', 'he', 've', 'οκ', 'avic', 'ashed', 'LOWER', ' intersections']\n",
      "Value vec: Layer 3, index 2045\n",
      "['achines', '.GetBytes', ' Nas', 'estone', 'mav', 'ses', '날', ' convention', 'emma', '-faced']\n",
      "Value vec: Layer 24, index 29\n",
      "['ummings', 'ovny', '伏', 'aeda', 'μον', 'ST', 'alus', 'บาย', ' surrogate', 'hire']\n",
      "Value vec: Layer 1, index 1775\n",
      "['orie', 'iens', 'ebo', 'oria', 'ORIA', 'ADO', ' yans', '646', 'agu', 'ado']\n",
      "Value vec: Layer 5, index 2916\n",
      "['ONY', 'ony', ' Carnegie', '徒', ' deb', 'лю', ' Duty', ' Toledo', '楽', 'ut']\n",
      "Value vec: Layer 85, index 262\n",
      "[' Cous', 'code', 'dam', '862', '775', 'aine', 'exact', ' dam', ' Biom', 'rene']\n",
      "Value vec: Layer 56, index 2225\n",
      "['igs', 'ably', 'apr', 'fully', '頼', ' Carol', 'ardi', 'asley', ' Leone', '160']\n",
      "Value vec: Layer 67, index 1922\n",
      "['fav', ' boyc', ' setCurrent', ' �', ' adoption', ' Adoption', 'غل', ' Bott', 'DI', 'adian']\n",
      "Value vec: Layer 9, index 3528\n",
      "['quate', 'ssf', 'mant', 'qua', ' Mig', 'ute', 'vinc', 'IPH', '107', '응']\n",
      "Value vec: Layer 3, index 819\n",
      "['utow', 'jis', '.Apis', 'ertino', 'ěle', 'ulia', 'tested', '.Binding', 'andler', ' арми']\n",
      "Value vec: Layer 107, index 1211\n",
      "['iba', 'Mvc', ' @}', 'urg', 'fy', 'stag', 'ruits', 'rens', 'ampa', 'orce']\n",
      "Value vec: Layer 2, index 3395\n",
      "['sembl', 'zer', 'airo', 'oulouse', 'aira', 'impan', 'asco', 'bage', '.TableLayoutPanel', 'iltro']\n",
      "Value vec: Layer 0, index 20\n",
      "[' Dumpster', '.hxx', 'herited', 'PLATFORM', 'IGGER', '.ant', '폭', 'edian', '.RightToLeft', 'pear']\n",
      "Value vec: Layer 2, index 1820\n",
      "['lessly', '_COMPAT', 'Ahead', 'rema', ' Probe', ' bitter', 'FUL', '��', 'fu', 'ILITY']\n",
      "Value vec: Layer 77, index 3645\n",
      "['ania', 'dsp', 'mand', 'saldo', ' Gupta', ' cries', 'edom', 'bjerg', ' Nab', 'алу']\n",
      "Value vec: Layer 13, index 133\n",
      "['iaux', ' BOTTOM', '��', 'agine', 'éli', ' Bottom', 'ensa', 'udy', ' overdue', '้าว']\n",
      "Value vec: Layer 95, index 2753\n",
      "['hart', '203', 'cheng', 'brig', 'وغ', 'uh', ' operator', 'ova', '興', ' operators']\n",
      "Value vec: Layer 107, index 64\n",
      "['FormData', 'uen', ' colum', 'assis', ' Garrison', 'انس', 'lish', ' Dop', ' Gian', 'les']\n",
      "Value vec: Layer 52, index 1492\n",
      "['vr', 'unic', '鳴', 'arp', 'arna', 'annah', 'aget', 'uj', 'ophy', 'ific']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "pos_vec = pos_embed - neg_embed\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), pos_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f127b67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FullScreen', ' Erd', 'Parms', ' rich', ' Lester', 'iani', 'Uvs', 'aty', ' Richards', 'ongs']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(pos_vec, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff58fd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 62, index 1457\n",
      "['dou', '_behavior', 'pine', ' Race', 'peq', 'بان', 'StartPosition', 'arna', 'odata', 'hti']\n",
      "Value vec: Layer 0, index 3581\n",
      "['endale', 'LocalizedString', '�', 'imli', 'abella', 'abric', 'еди', 'endon', 'ogue', 'gre']\n",
      "Value vec: Layer 26, index 1533\n",
      "['REFER', '.addObject', ' pokoj', 'viders', 'quee', 'otte', 'prs', 'UNET', ' Dalton', 'kehr']\n",
      "Value vec: Layer 7, index 1705\n",
      "['�', 'tat', 'iginal', 'earn', 'erif', 'phin', ' Conway', 'ropol', 'MMdd', 'aña']\n",
      "Value vec: Layer 66, index 3597\n",
      "['クセ', 'weeney', 'antu', ' eğ', '?><?', 'ometr', 'uhan', 'ンバ', 'アー', 'chl']\n",
      "Value vec: Layer 28, index 564\n",
      "['筋', ' haus', ' Haw', 'ello', 'atu', '233', 'ore', ' priv', 'πο', ' presidency']\n",
      "Value vec: Layer 33, index 2083\n",
      "['pom', ' discret', '선', 'aram', 'arme', 'ltk', 'WF', 'ilha', 'dej', 'αρ']\n",
      "Value vec: Layer 105, index 2332\n",
      "['ột', 'apat', 'ős', ' bumped', ' Parcel', 'chas', 'appe', ' mpg', ' Cal', ' gep']\n",
      "Value vec: Layer 8, index 2709\n",
      "['riott', 'ンティ', '[section', 'avel', 'Multiplicity', '483', 'ktop', ' trav', 'ipay', 'vek']\n",
      "Value vec: Layer 98, index 3376\n",
      "['abeth', 'igne', ' Verfüg', 'inou', '.addObserver', 'jax', 'iec', 'ye', 'usercontent', 'uncios']\n",
      "Value vec: Layer 96, index 195\n",
      "[' mountain', ' Mountain', ' mountains', 'Mountain', 'mount', '山', ' Mountains', 'Mount', 'ountain', ' mount']\n",
      "Value vec: Layer 3, index 1232\n",
      "['irling', 'zeitig', ' defaultMessage', 'opp', 'alian', 'chez', 'urge', '/Branch', 'frau', 'izzo']\n",
      "Value vec: Layer 2, index 3899\n",
      "['zb', 'izoph', 'urette', 'icast', 'angelo', 'fen', 'oret', ' directions', 'roman', 'chant']\n",
      "Value vec: Layer 55, index 1968\n",
      "[' lead', 'plat', 'UME', 'ylko', ' wirk', 'っぱ', ' kontakte', 'éra', 'ço', 'wers']\n",
      "Value vec: Layer 8, index 1485\n",
      "['uhl', ' Concurrent', ' Hart', ' Ther', ' Goldberg', 'fy', 'ieten', ' Coleman', ' extras', ' probe']\n",
      "Value vec: Layer 71, index 3249\n",
      "[' as', ' like', ' как', ' كما', ' 如', ' Like', ' zoals', ' wie', '如', '，如']\n",
      "Value vec: Layer 75, index 2728\n",
      "['.scalablytyped', 'entence', 'uhan', 'undef', 'esser', 'eses', 'ken', '�', 'dí', 'ften']\n",
      "Value vec: Layer 31, index 2882\n",
      "[' Habit', 'deps', ' ReturnType', ' Reyn', '637', ' RTS', ' habit', 'ì', 'Nam', '/helper']\n",
      "Value vec: Layer 47, index 1803\n",
      "[' cle', 'рь', 'MSN', ' Cle', 'urette', 'andler', 'Mine', 'ンプ', ' �', 'cket']\n",
      "Value vec: Layer 48, index 3068\n",
      "['ventus', 'coma', ' подв', 'ipay', 'ontent', ' grav', ' Ney', 'orld', 'isclosed', 'ogie']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "neg_vec = neg_embed - pos_embed \n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), neg_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e7ccde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/desktop', 'oton', 'bourne', 'oph', 'ine', ' чин', '981', 'ount', ' Duel', 'orp']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(neg_vec, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8521ec4",
   "metadata": {},
   "source": [
    "#### Gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83f84183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534edb6a5bef425c90cef7c38ef8bbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2-2b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afaf3703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239616, 2304])\n"
     ]
    }
   ],
   "source": [
    "token_embeds = model.model.embed_tokens.weight\n",
    "value_vectors = torch.cat(\n",
    "    [\n",
    "        model.model.layers[layer_idx].mlp.down_proj.weight.T\n",
    "        for layer_idx in range(model.config.num_hidden_layers)\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "print(value_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec79f611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive token IDs: [11896, 3375, 4915, 10300, 11491]\n",
      "Negative token IDs: [9270, 19456, 41497]\n"
     ]
    }
   ],
   "source": [
    "seed_token_pos = [\"happy\", \"joy\", \" happy\", \" joy\", \" smile\"]\n",
    "seed_token_neg = [\" sad\", \" angry\", \" disgust\"]\n",
    "\n",
    "pos_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_pos\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "neg_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_neg\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "print(\"Positive token IDs:\", pos_token_id)\n",
    "print(\"Negative token IDs:\", neg_token_id)\n",
    "\n",
    "pos_embed = token_embeds[pos_token_id].mean(dim=0)\n",
    "neg_embed = token_embeds[neg_token_id].mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60c2c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unembed_to_text(vector, model, tokenizer, k=10):\n",
    "    norm = model.model.norm  \n",
    "    lm_head = model.lm_head.weight\n",
    "\n",
    "    normed_vector = norm(vector.unsqueeze(0)).squeeze(0)  # shape: [d_model]\n",
    "\n",
    "    dots = torch.einsum(\"vd,d->v\", lm_head, normed_vector)\n",
    "\n",
    "    top_k = dots.topk(k).indices\n",
    "    return tokenizer.batch_decode(top_k, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d827f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 54, index 3627\n",
      "[' happy', ' Happy', 'Happy', 'happy', ' HAPPY', 'HAPPY', ' happiest', ' happier', ' happiness', ' satisfied']\n",
      "Value vec: Layer 49, index 3230\n",
      "[' happy', 'happy', ' Happy', 'Happy', ' HAPPY', 'HAPPY', ' happier', ' happiest', ' happily', ' feliz']\n",
      "Value vec: Layer 47, index 192\n",
      "[' happy', 'happy', ' happiness', ' sad', ' unhappy', ' Happy', ' HAPPY', ' sadness', ' happiest', ' unhappiness']\n",
      "Value vec: Layer 51, index 3146\n",
      "[' happy', ' joyful', ' joy', ' rejoice', ' cheerful', ' happiness', ' joyous', ' celebratory', ' pleasant', ' rejoicing']\n",
      "Value vec: Layer 41, index 3916\n",
      "[' Happy', 'Happy', ' happy', ' HAPPY', 'happy', 'HAPPY', ' feliz', ' happier', ' happiest', ' Feliz']\n",
      "Value vec: Layer 56, index 2644\n",
      "[' enjoyment', ' Enjoy', ' enjoy', 'enjoy', 'Enjoy', ' ENJOY', ' enjoyed', ' enjoying', ' enjoyable', ' pleasure']\n",
      "Value vec: Layer 40, index 3812\n",
      "[' enjoyment', ' pleasure', ' Enjoy', ' enjoy', ' enjoyable', 'enjoy', 'Enjoy', ' ENJOY', ' Pleasure', ' joy']\n",
      "Value vec: Layer 36, index 3892\n",
      "[' happy', ' joyous', ' joy', ' joyful', ' happiness', ' delighted', ' celebratory', 'joyed', ' overjoyed', 'happy']\n",
      "Value vec: Layer 40, index 2269\n",
      "[' successes', ' delighted', ' joy', ' triumph', ' joyful', ' success', ' triumphant', ' rejoice', ' triumphs', ' overjoyed']\n",
      "Value vec: Layer 46, index 619\n",
      "[' pleasure', 'pleasure', ' Pleasure', ' privilege', ' plaisir', ' joy', ' honor', ' prazer', ' PLEAS', ' pleasures']\n",
      "Value vec: Layer 43, index 2512\n",
      "[' happy', ' glad', 'happy', ' gladly', ' HAPPY', ' heureux', ' Happy', ' defaultstate', ' delighted', 'glad']\n",
      "Value vec: Layer 42, index 2419\n",
      "[' glad', ' Glad', 'Glad', 'glad', ' pleased', ' happy', ' delighted', ' GLAD', ' pleasure', ' nice']\n",
      "Value vec: Layer 44, index 2915\n",
      "[' positive', ' optimistic', ' optimism', ' Positive', 'Positive', 'positive', ' Optimis', ' optim', ' positivity', 'optimis']\n",
      "Value vec: Layer 39, index 1072\n",
      "[' carefree', ' lightness', ' cheerful', ' lighten', ' joyful', ' lightest', ' lighter', ' frivolous', ' airy', ' breezy']\n",
      "Value vec: Layer 42, index 2050\n",
      "[' fun', 'fun', 'Fun', ' Fun', ' FUN', 'FUN', ' divertido', ' divertimento', ' diversión', ' Spaß']\n",
      "Value vec: Layer 47, index 2370\n",
      "[' glad', 'glad', ' Glad', 'Glad', ' GLAD', ' happy', ' thankful', ' Happy', ' grateful', ' thank']\n",
      "Value vec: Layer 40, index 1863\n",
      "[' celebration', ' celebratory', ' celebrate', ' celebrating', ' celebrations', ' Celebration', 'celebr', 'celebrate', 'Celebration', ' Celebrations']\n",
      "Value vec: Layer 43, index 1515\n",
      "[' proud', ' pleased', 'proud', ' heureux', ' happy', ' Proud', 'Proud', ' heureuse', ' excited', ' proudly']\n",
      "Value vec: Layer 8, index 2928\n",
      "[' disappointed', ' tevreden', ' dissatisfied', ' dissatisfaction', ' disappointment', ' satisfaction', ' Satisfaction', ' zufrieden', ' pleased', ' displeased']\n",
      "Value vec: Layer 50, index 1972\n",
      "[' enjoy', ' Enjoy', 'enjoy', ' enjoyed', ' enjoying', ' enjoys', 'Enjoy', ' ENJOY', ' enjoyment', 'ENJOY']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "pos_vec = pos_embed - neg_embed\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), pos_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58904553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 42, index 3907\n",
      "['aarrggbb', ' Dalio', 'VersionUID', ' ✭✭', 'IsMutable', ' ComVisible', ' AssemblyProduct', ' AFB', 'optString', 'uxxxx']\n",
      "Value vec: Layer 43, index 3726\n",
      "[' GenerationType', 'rotech', ' AssemblyCulture', '::$_', ' BoxDecoration', 'GenerationType', ' Auk', 'ereço', 'Artem', 'endphp']\n",
      "Value vec: Layer 44, index 1954\n",
      "[' Vikipedi', 'balleur', ' تضيفلها', ' lenker', 'UnknownFieldSet', 'thâu', 'ajara', ' Loh', 'nestjs', 'LVANIA']\n",
      "Value vec: Layer 39, index 2649\n",
      "[' mica', ' curio', ' oignon', ' cin', ' McIn', 'weiler', 'Интере', ' Curious', 'Quo', '!*\\\\']\n",
      "Value vec: Layer 39, index 4088\n",
      "['extAlignment', ' NgModule', 'GenerationType', ' bidra', 'EndContext', 'int', ' SqlCommand', ' degradability', 'Thing', 'IContainer']\n",
      "Value vec: Layer 56, index 25\n",
      "['bParam', ' تضيفلها', 'openzeppelin', 'tvguidetime', ' Pala', 'reactivex', 'ArrowToggle', ' creen', 'twimg', '@\",']\n",
      "Value vec: Layer 43, index 2877\n",
      "[' sī', 'ритори', 'bootstrapcdn', '=>$', 'enumii', ' AssemblyTitle', 'olella', 'MigrationBuilder', ')|^{', '이버']\n",
      "Value vec: Layer 41, index 4029\n",
      "[' Beds', ' Bed', ' headboard', ' bedded', 'Sleeping', ' Luton', ' beds', 'chamber', ' mattress', 'BED']\n",
      "Value vec: Layer 37, index 2699\n",
      "['Tazama', ' problem', ')=-\\\\', 'onerror', ' troubles', ' probleem', ' considérons', ' disapproval', '못', 'Ouch']\n",
      "Value vec: Layer 38, index 2909\n",
      "['BeginContext', 'CHAFT', 'prese', 'bouncycastle', 'uset', 'esModule', ' LLVM', 'ensement', 'quées', 'Koordinaten']\n",
      "Value vec: Layer 48, index 1244\n",
      "['aarrggbb', ' onCancelled', 'mobileqq', 'reactstrap', ' sifat', 'dropna', 'Lähteet', 'liferay', 'cche', 'meable']\n",
      "Value vec: Layer 9, index 3772\n",
      "['EndTag', 'EndInit', ' CURLOPT', 'seamnă', 'argout', ' nakalista', 'AnchorStyles', 'StructEnd', 'stateProvider', ' صوتيه']\n",
      "Value vec: Layer 56, index 1684\n",
      "[' Domain', ' domain', 'Domain', ' Domains', ' domains', 'domain', ' DOMAIN', 'Domains', 'DOMAIN', 'domains']\n",
      "Value vec: Layer 57, index 2177\n",
      "['/*++', 'principalColumn', 'OrNil', 'quiti', '🔙', ' المعيارى', ' فريبيس', ' referrerpolicy', 'findpost', 'TEMPO']\n",
      "Value vec: Layer 41, index 3201\n",
      "[' FontWeight', 'tvguidetime', ' @{', ' Signalez', 'esModule', '\\ufeff#', 'oa̍t', ' ważne', 'AndEndTag', ' doInBackground']\n",
      "Value vec: Layer 38, index 990\n",
      "[' fools', 'iculous', ' Freih', ' pretend', 'ậy', 'usammen', 'gele', ' hábito', ' kohta', 'Последние']\n",
      "Value vec: Layer 51, index 1921\n",
      "['UnknownFieldSet', 'aarrggbb', 'ChildScrollView', ' propOrder', 'InjectAttribute', 'ReactDOM', 'AccessorTable', 'migrationBuilder', 'Rptr', ' Hotspot']\n",
      "Value vec: Layer 41, index 3121\n",
      "['ніципа', 'Искәрмәләр', 'ⓧ', ' autorytatywna', 'BeginContext', '권', 'AddTagHelper', ' intptr', ' советы', 'éis']\n",
      "Value vec: Layer 38, index 2875\n",
      "['Judi', 'nė', 'lenül', 'وعة', 'clearTimeout', ' geschlagen', ' للاسماء', 'schuhe', 'tawesome', 'ారి']\n",
      "Value vec: Layer 32, index 3877\n",
      "['ServletRequest', ' विश्वसनीयता', 'LabelTagHelper', 'fstream', 'ंदीखरीदारी', 'LocationManager', 'netinet', 'sidemargin', ' setDescription', ' rând']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "neg_vec = neg_embed - pos_embed \n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), neg_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c85a02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' happy', 'happy', ' joy', ' Happy', 'Happy', 'joy', ' HAPPY', 'HAPPY', ' happiness', ' smile']\n",
      "['Dom', 'astic', ' distin', ' Dom', 'dom', ' dom', 'DOM', ' DOM', ' distinctive', ' distingu']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(pos_vec, model, tokenizer))\n",
    "print(unembed_to_text(neg_vec, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b270ee",
   "metadata": {},
   "source": [
    "#### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8591894f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947cb6d7d6ac4e62bac65b18655cee3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff999cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([458752, 4096])\n"
     ]
    }
   ],
   "source": [
    "token_embeds = model.model.embed_tokens.weight\n",
    "value_vectors = torch.cat(\n",
    "    [\n",
    "        model.model.layers[layer_idx].mlp.down_proj.weight.T\n",
    "        for layer_idx in range(model.config.num_hidden_layers)\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "print(value_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f300cad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive token IDs: [4610, 10186, 4610, 10186, 6458]\n",
      "Negative token IDs: [7456, 10545, 21536]\n"
     ]
    }
   ],
   "source": [
    "seed_token_pos = [\"happy\", \"joy\", \" happy\", \" joy\", \" smile\"]\n",
    "seed_token_neg = [\" sad\", \" angry\", \" disgust\"]\n",
    "\n",
    "pos_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_pos\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "neg_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_neg\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "print(\"Positive token IDs:\", pos_token_id)\n",
    "print(\"Negative token IDs:\", neg_token_id)\n",
    "\n",
    "pos_embed = token_embeds[pos_token_id].mean(dim=0)\n",
    "neg_embed = token_embeds[neg_token_id].mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9a6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unembed_to_text(vector, model, tokenizer, k=10):\n",
    "    norm = model.model.norm  \n",
    "    lm_head = model.lm_head.weight\n",
    "\n",
    "    normed_vector = norm(vector.unsqueeze(0)).squeeze(0)  # shape: [d_model]\n",
    "\n",
    "    dots = torch.einsum(\"vd,d->v\", lm_head, normed_vector)\n",
    "\n",
    "    top_k = dots.topk(k).indices\n",
    "    return tokenizer.batch_decode(top_k, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d8f576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 5, index 749\n",
      "['당', 'anza', 'führ', 'enas', 'mals', 'acz', 'amas', 'agi', 'arin', 'atos']\n",
      "Value vec: Layer 2, index 2113\n",
      "['pty', 'eras', 'ea', 'atique', 'Oz', 'sop', 'stag', 'onne', 'lug', 'ante']\n",
      "Value vec: Layer 1, index 1075\n",
      "['smile', 'smiling', 'smiled', 'smiles', 'grin', 'reed', 'Sm', 'fx', 'lish', 'undo']\n",
      "Value vec: Layer 20, index 3217\n",
      "['happiness', 'joy', 'joy', 'smiles', 'happ', 'eb', 'happy', 'anda', 'smile', 'happily']\n",
      "Value vec: Layer 2, index 800\n",
      "['usk', 'inton', 'PARTICULAR', 'loyd', 'hire', 'appy', 'ERCHANT', 'sung', 'enth', 'gom']\n",
      "Value vec: Layer 0, index 2453\n",
      "['heimer', 'eno', 'ws', 'ERN', 'ENO', 'Franc', 'shipped', 'uelle', 'ou', 'owi']\n",
      "Value vec: Layer 7, index 1075\n",
      "['joy', 'joy', 'Joy', 'borg', 'Dru', 'ris', 'eria', 'eres', 'prem', 'owe']\n",
      "Value vec: Layer 0, index 345\n",
      "['pleasure', 'éri', 'printStackTrace', 'allo', 'GRO', 'iba', 'unexpected', 'println', 'har', 'Kevin']\n",
      "Value vec: Layer 16, index 2478\n",
      "['eph', 'Agency', 'cheek', 'stor', 'colo', 'colour', 'chet', 'Chron', 'chosen', 'arte']\n",
      "Value vec: Layer 2, index 3851\n",
      "['lam', 'Nur', 'izontal', 'uchar', 'entry', 'ugu', 'parallel', 'Pattern', 'dumb', 'tn']\n",
      "Value vec: Layer 51, index 301\n",
      "['triumph', 'vict', 'cheer', '/******/', 'victory', 'celebr', 'etti', 'rejo', 'reich', 'enth']\n",
      "Value vec: Layer 2, index 1433\n",
      "['ren', 'isterschaft', 'etch', 'sid', 'late', 'oubt', 'suck', 'cite', 'är', 'äck']\n",
      "Value vec: Layer 10, index 1390\n",
      "['beds', 'Ludwig', 'Lo', 'conj', 'litter', 'ers', 'scal', 'horizon', 'lez', 'DL']\n",
      "Value vec: Layer 20, index 2673\n",
      "['coup', 'ellen', 'eled', 'ļ', 'Lad', 'GS', 'intervention', 'Pred', 'mission', 'asi']\n",
      "Value vec: Layer 7, index 1497\n",
      "['kö', 'arsi', 'atform', 'raison', 'Tu', '担', 'Bah', 'scarc', 'pha', 'TT']\n",
      "Value vec: Layer 67, index 572\n",
      "['hund', 'rost', 'nehmen', 'ợ', 'lear', 'edges', 'ply', 'usher', 'Candidate', 'кры']\n",
      "Value vec: Layer 68, index 2267\n",
      "['Hit', 'xp', 'Isabel', 'volution', 'dom', 'sock', 'elbow', 'XFF', 'ölker', 'ześ']\n",
      "Value vec: Layer 0, index 2674\n",
      "['Craw', 'ény', 'inda', 'bw', 'omic', 'Het', 'arsi', 'cí', 'anos', 'plex']\n",
      "Value vec: Layer 2, index 47\n",
      "['>{@', 'bet', 'oen', 'ppen', 'erten', 'iko', 'pler', 'multicol', 'érc', 'iores']\n",
      "Value vec: Layer 0, index 2106\n",
      "['sto', 'Balt', 'ijn', 'Dor', 'bet', 'cken', 'ja', 'camp', 'jet', 'ner']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "pos_vec = pos_embed - neg_embed\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), pos_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e96f73d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 3, index 1096\n",
      "['conting', 'implicit', 'endorse', 'ague', 'powered', 'swe', 'dist', '력', 'па', '\\\\_']\n",
      "Value vec: Layer 3, index 1257\n",
      "['iera', 'même', 'mutable', 'iesa', 'ele', 'Tube', 'havet', 'chter', 'Lad', 'nero']\n",
      "Value vec: Layer 11, index 3465\n",
      "['iri', 'vir', 'digest', 'Bes', 'honey', 'саве', 'cold', 'alth', 'Grand', 'akten']\n",
      "Value vec: Layer 9, index 3089\n",
      "['лове', 'yle', '�', 'Cape', 'Sec', 'vers', 'routine', 'mann', 'uch', 'xE']\n",
      "Value vec: Layer 21, index 1881\n",
      "['Castle', 'cola', 'onna', 'ieron', 'Bast', 'uum', 'odio', 'шен', 'ikel', 'preview']\n",
      "Value vec: Layer 53, index 1957\n",
      "['aude', 'Tol', 'aw', 'caused', 'ASS', 'awi', 'auf', 'ond', 'MAGES', 'climb']\n",
      "Value vec: Layer 14, index 917\n",
      "['occupied', 'Buck', 'hint', 'lazy', 'ilt', 'uso', 'abled', 'cure', 'PC', 'geldig']\n",
      "Value vec: Layer 0, index 2461\n",
      "['come', 'ton', 'egründ', 'cov', 'début', 'commence', 'deeply', 'iom', 'intro', 'Haupt']\n",
      "Value vec: Layer 1, index 1384\n",
      "['passage', 'ív', 'spell', 'spell', 'bread', 'ńst', 'ont', 'embed', 'passive', 'ová']\n",
      "Value vec: Layer 22, index 2106\n",
      "['otta', 'ento', 'cken', 'lif', 'isen', 'cock', 'rès', 'ega', 'ppe', 'upright']\n",
      "Value vec: Layer 28, index 1832\n",
      "['shr', 'attachment', 'ude', 'incent', 'heap', 'mater', 'uable', 'Ren', 'matic', 'vain']\n",
      "Value vec: Layer 89, index 3522\n",
      "['Round', 'ida', 'izia', 'nen', 'Fourth', 'States', 'olic', 'rounds', 'ghost', 'Ghost']\n",
      "Value vec: Layer 10, index 3770\n",
      "['woh', 'Bus', 'Dot', '司', 'Astr', 'scrub', 'etta', 'bus', 'Aires', 'airs']\n",
      "Value vec: Layer 4, index 2113\n",
      "['oler', 'recated', 'uminate', 'ĩ', 'TT', 'avelength', 'rought', 'rera', 'nate', 'や']\n",
      "Value vec: Layer 1, index 1353\n",
      "['RF', 'iami', 'wick', 'enta', 'Muse', 'ento', 'DED', 'hard', 'egen', 'itol']\n",
      "Value vec: Layer 21, index 1148\n",
      "['view', 'allet', 'icus', 'fair', 'Ath', 'ugno', 'RW', 'chain', 'jar', 'neutral']\n",
      "Value vec: Layer 25, index 2159\n",
      "['dri', 'FMT', 'intim', '�', 'mon', 'station', 'berger', 'spe', 'bbra', 'pu']\n",
      "Value vec: Layer 16, index 2435\n",
      "['MC', 'UN', 'dop', 'Gordon', 'summit', 'rik', 'ysk', 'jon', 'igo', 'reflected']\n",
      "Value vec: Layer 96, index 1856\n",
      "['m', 'м', 'M', 'М', 'Μ', 'mf', 'mé', 'oge', 'MD', 'mn']\n",
      "Value vec: Layer 48, index 554\n",
      "['aki', 'Village', 'pu', 'sophistic', 'ouw', 'independent', 'kre', 'erde', 'hem', '端']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "neg_vec = neg_embed - pos_embed \n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), neg_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9218a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/******/', 'acci', 'anco', '干', 'XR', 'ISH', 'aco', 'charg', 'XFF', 'brace']\n",
      "['ronic', 'fruit', 'Bron', '体', 'final', 'ron', 'ret', 'flesh', 'pson', 'Pear']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(pos_vec, model, tokenizer))\n",
    "print(unembed_to_text(neg_vec, model, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
