{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b72fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer\n",
    "from fancy_einsum import einsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a926b9b",
   "metadata": {},
   "source": [
    "#### GPT2-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfb26b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "toxic_probe = torch.load(\"/data/kebl6672/dpo-toxic-general/checkpoints/gpt2_lee_probe.pt\").cuda(0)\n",
    "toxic_probe = toxic_probe.squeeze(0)\n",
    "print(toxic_probe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36bdecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-medium\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).cuda(0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55bb7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([98304, 1024])\n"
     ]
    }
   ],
   "source": [
    "token_embeds = model.transformer.wte.weight\n",
    "value_vectors = torch.cat(\n",
    "    [\n",
    "        model.transformer.h[layer_idx].mlp.c_proj.weight\n",
    "        for layer_idx in range(model.config.num_hidden_layers)\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "print(value_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5befea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic token IDs: [31699, 16211]\n",
      "Non-toxic token IDs: [31373, 27547, 6726, 22988]\n"
     ]
    }
   ],
   "source": [
    "seed_token_toxic = [\"fuck\", \"shit\", \"crap\"]\n",
    "seed_token_non_toxic = [\"hello\", \"thanks\", \"friend\", \"peace\", \"welcome\"]\n",
    "\n",
    "toxic_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_toxic\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "non_toxic_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_non_toxic\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "print(\"Toxic token IDs:\", toxic_token_id)\n",
    "print(\"Non-toxic token IDs:\", non_toxic_token_id)\n",
    "\n",
    "toxic_embed = token_embeds[toxic_token_id].mean(dim=0)\n",
    "non_toxic_embed = token_embeds[non_toxic_token_id].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d66cf1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unembed_to_text(vector, model, tokenizer, k=10):\n",
    "    norm = model.transformer.ln_f\n",
    "    lm_head = model.lm_head.weight\n",
    "    dots = einsum(\"vocab d_model, d_model -> vocab\", lm_head, norm(vector))\n",
    "    top_k = dots.topk(k).indices\n",
    "    return tokenizer.batch_decode(top_k, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a1012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 19, index 770\n",
      "[' shit', ' ass', ' crap', ' fuck', ' garbage', ' asses', ' cunt', ' trash', ' dick', 'shit']\n",
      "Value vec: Layer 12, index 882\n",
      "['fuck', ' shit', ' piss', 'Fuck', ' hilar', 'shit', ' stupidity', ' poop', ' shitty', ' stupid']\n",
      "Value vec: Layer 15, index 659\n",
      "[' dudes', ' stuff', ' dude', ' shit', ' kinda', ' fuckin', ' goddamn', ' badass', ' blah', ' pretty']\n",
      "Value vec: Layer 17, index 2877\n",
      "[' kinda', ' stuff', ' fuckin', ' guys', ' yeah', ' gonna', ' dudes', ' crap', ' gotta', ' guy']\n",
      "Value vec: Layer 13, index 4065\n",
      "[' fuck', ' fucking', ' piss', ' goddamn', ' shit', ' godd', ' damned', ' damn', ' crap', ' shri']\n",
      "Value vec: Layer 19, index 1767\n",
      "[' fucking', ' dudes', ' fuckin', ' goddamn', ' shit', ' shitty', ' dude', ' kinda', ' guys', ' gotta']\n",
      "Value vec: Layer 7, index 3358\n",
      "[' crap', ' shri', ' shit', ' whine', ' Godd', ' bullshit', ' gigg', ' euphem', ' goddamn', 'uphem']\n",
      "Value vec: Layer 8, index 1079\n",
      "[' crap', ' dudes', ' kinda', ' dude', ' crappy', ' guys', ' guy', ' stuff', ' pissed', ' shit']\n",
      "Value vec: Layer 14, index 883\n",
      "[' fuck', ' FUCK', 'HAHA', 'HAHAHAHA', ' hell', 'fuck', 'oooooooooooooooo', 'Fuck', ' wow', ' Fuck']\n",
      "Value vec: Layer 15, index 2071\n",
      "[' shit', ' balls', ' stink', ' stares', ' laughs', ' heaven', ' smile', ' ble', ' disappointment', ' awful']\n",
      "Value vec: Layer 22, index 1728\n",
      "['ricular', 'andom', 'worms', 'sp', ' cause', 'oop', ' gir', 'PLIC', ' overfl', ' Ferry']\n",
      "Value vec: Layer 19, index 1438\n",
      "[' cum', ' cock', ' orgasm', ' bondage', ' anal', ' missionary', ' org', ' fucked', 'ildo', ' arousal']\n",
      "Value vec: Layer 2, index 610\n",
      "[' rant', ' cliché', ' crap', ' bullshit', ' badass', ' stupidity', ' goof', ' nerd', ' shitty', ' Freak']\n",
      "Value vec: Layer 19, index 1124\n",
      "[' stuff', ' crap', ' crappy', ' pissed', ' guy', ' guys', ' shit', ' kinda', ' shitty', ' Stuff']\n",
      "Value vec: Layer 16, index 974\n",
      "[' inappropriately', ' prejud', ' unnecessarily', ' improperly', ' unchecked', ' incorrectly', ' inefficient', ' miscon', ' arrogance', ' excessively']\n",
      "Value vec: Layer 7, index 512\n",
      "[' comprom', 'ه', ' Constantin', ' Rollins', ' Clover', ' ¯', ' Wikimedia', 'amera', 'Fuck', ' NX']\n",
      "Value vec: Layer 2, index 1052\n",
      "['fuck', ' hairc', 'agogue', ' Twisted', ' Flavoring', ' cousins', 'bling', 'ency', 'ocket', ' weave']\n",
      "Value vec: Layer 12, index 771\n",
      "[' delusional', ' hypocritical', ' delusions', ' arrogant', ' nonsense', ' rubbish', ' hypocr', ' childish', ' libel', ' insulting']\n",
      "Value vec: Layer 18, index 491\n",
      "[' ever', ' EVER', ' CONC', 'isitions', ' thing', 'waters', ' penn', ' dip', 'edi', 'hoe']\n",
      "Value vec: Layer 7, index 4043\n",
      "['anwhile', ' screaming', 'gey', ' bark', 'illac', 'ossip', 'erella', ' shack', 'osaurus', ' scree']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 20\n",
    "norm = model.transformer.ln_f\n",
    "\n",
    "target_vec = toxic_embed - non_toxic_embed\n",
    "dot_prods = einsum(\"value_vecs d_model, d_model -> value_vecs\", norm(value_vectors), target_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a19de55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shit', 'fuck', 'Fuck', ' fuck', ' shit', ' Fuck', ' Shit', ' fucking', ' FUCK', ' fucked']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(target_vec, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58edd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(target_vec, 'gpt2_toxic_embed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cdff046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 19, index 770\n",
      "[' shit', ' ass', ' crap', ' fuck', ' garbage', ' asses', ' cunt', ' trash', ' dick', 'shit']\n",
      "Value vec: Layer 12, index 771\n",
      "[' delusional', ' hypocritical', ' delusions', ' arrogant', ' nonsense', ' rubbish', ' hypocr', ' childish', ' libel', ' insulting']\n",
      "Value vec: Layer 18, index 2669\n",
      "[' degener', ' whining', ' stupid', ' smug', ' foolish', ' idiots', ' stupidity', ' lies', ' hypocr', ' idiot']\n",
      "Value vec: Layer 13, index 668\n",
      "[' losers', ' filthy', ' disgr', ' gad', ' mor', ' feces', ' cess', ' disgrace', ' apes', ' unworthy']\n",
      "Value vec: Layer 16, index 255\n",
      "[' disgrace', ' shameful', ' coward', ' unacceptable', ' despicable', ' barbaric', ' cowardly', ' irresponsible', ' disgusting', ' immoral']\n",
      "Value vec: Layer 12, index 882\n",
      "['fuck', ' shit', ' piss', 'Fuck', ' hilar', 'shit', ' stupidity', ' poop', ' shitty', ' stupid']\n",
      "Value vec: Layer 19, index 1438\n",
      "[' cum', ' cock', ' orgasm', ' bondage', ' anal', ' missionary', ' org', ' fucked', 'ildo', ' arousal']\n",
      "Value vec: Layer 9, index 545\n",
      "['azel', ' nodd', ' bucket', ' shack', ' chuck', 'otomy', ' bitch', ' jaws', ' horny', ' kettle']\n",
      "Value vec: Layer 11, index 1550\n",
      "[' heavens', ' dear', ' earthly', ' cannabin', ' blessed', ' paradise', 'ankind', ' curtain', ' cosmos', 'ursed']\n",
      "Value vec: Layer 14, index 1958\n",
      "[' head', ' face', ' coffin', 'umbn', ' heads', ' chair', ' desk', ' skulls', ' Coffin', 'olesc']\n",
      "Value vec: Layer 8, index 2854\n",
      "['cond', ' senseless', ' humiliating', ' Tyrann', 'otaur', 'tery', 'kk', ' wasteful', ' unres', 'ulus']\n",
      "Value vec: Layer 3, index 3680\n",
      "[' sexist', ' feminist', ' Femin', 'femin', ' misogyn', ' inequalities', 'itivity', ' slurs', ' Feminist', ' femin']\n",
      "Value vec: Layer 13, index 1023\n",
      "[' vicious', ' humiliation', ' contempt', ' wasted', ' misery', ' sabotage', ' starving', ' sabot', ' shameless', ' extortion']\n",
      "Value vec: Layer 7, index 1735\n",
      "[' murd', 'SourceFile', ' tort', ' hairc', 'ror', ' FACE', 'wordpress', ' guts', 'hide', 'gery']\n",
      "Value vec: Layer 13, index 2258\n",
      "[' Manifest', ' Crusade', ' Blueprint', ' Clubs', ' eman', 'udo', ' Initiative', ' (/', ' collective', ' Countdown']\n",
      "Value vec: Layer 13, index 253\n",
      "[' dick', ' naughty', ' sausage', 'icles', ' boobs', 'icle', ' biscuits', ' pudding', ' poop', ' tongue']\n",
      "Value vec: Layer 11, index 2844\n",
      "[' nightmares', ' fries', ' unic', ' sandwiches', ' shri', ' underwear', ' puppies', ' fried', ' nap', ' unicorn']\n",
      "Value vec: Layer 10, index 3477\n",
      "[' passively', ' pleasure', 'ulum', 'hiba', ' castles', ' pleasures', ' gratification', ' beads', 'hess', ' monitors']\n",
      "Value vec: Layer 19, index 3341\n",
      "[' maniac', ' idiots', ' lizard', ' folk', ' lun', ' nut', ' ignor', ' folks', ' people', ' fools']\n",
      "Value vec: Layer 11, index 175\n",
      "[' nude', ' anal', ' genital', ' vagina', ' naked', ' sexually', ' breasts', ' vaginal', ' buttocks', ' genitals']\n",
      "Value vec: Layer 3, index 704\n",
      "[' Granger', ' Sanford', ' Snyder', ' Forth', ' Springfield', ' Tackle', ' showc', 'holes', ' motel', ' holster']\n",
      "Value vec: Layer 10, index 2936\n",
      "[' retaliation', '�', 'モ', ' Illegal', ' Creat', ' Competition', ' havoc', ' Nose', 'ULTS', ' SIG']\n",
      "Value vec: Layer 0, index 2352\n",
      "[' Instr', 'icago', ' incompet', 'IRD', 'sembly', ' strugg', 'enhagen', 'ascript', ' manners', ' newsp']\n",
      "Value vec: Layer 3, index 1656\n",
      "['isphere', ' nodd', ' fate', ' bashing', 'terness', 'itudes', ' pron', ' quot', 'rays', 'cum']\n",
      "Value vec: Layer 7, index 1916\n",
      "['rators', 'igree', 'yright', 'volent', 'ctors', 'awed', 'tackle', 'metic', 'fat', ' Owners']\n",
      "Value vec: Layer 11, index 2617\n",
      "[' Brist', ' comm', ' manag', ' drafting', ' COMPLE', '@#&', ' hygiene', ' Daniels', ' Answers', ' guiActiveUnfocused']\n",
      "Value vec: Layer 7, index 3358\n",
      "[' crap', ' shri', ' shit', ' whine', ' Godd', ' bullshit', ' gigg', ' euphem', ' goddamn', 'uphem']\n",
      "Value vec: Layer 3, index 3742\n",
      "[' pussy', ' orgasm', ' clitor', ' muscles', ' audition', ' penet', ' genitals', ' OFF', ' folds', ' arousal']\n",
      "Value vec: Layer 11, index 4021\n",
      "[' ejac', 'vag', 'FontSize', ' hormones', ' genital', ' orgasm', ' accuser', ' adultery', ' ultrasound', ' intercourse']\n",
      "Value vec: Layer 11, index 3414\n",
      "[' sucker', ' hilar', ' crap', ' shenanigans', ' nasty', ' nifty', 'sort', ' loser', ' stupidity', ' pesky']\n",
      "Value vec: Layer 13, index 1544\n",
      "[' godd', ' Dise', ' Buckingham', ' Niet', ' fucking', ' goddamn', ' Conway', ' Monsanto', ' sixty', ' seventy']\n",
      "Value vec: Layer 8, index 3200\n",
      "['nam', ' mund', 'ativity', 'ided', 'atical', 'atically', ' Yug', ' TAMADRA', 'ð', ' wid']\n",
      "Value vec: Layer 15, index 1696\n",
      "[' death', ' extermination', ' decap', ' Corpse', ' slaughter', ' torture', ' steril', ' dism', ' corpses', ' destruction']\n",
      "Value vec: Layer 20, index 3210\n",
      "[' Sloven', ' prick', ' Pole', ' mor', ' shif', ' sto', ' tatt', 'ザ', ' Yugoslav', ' rept']\n",
      "Value vec: Layer 5, index 1744\n",
      "['fer', ' Nig', ' Bastard', ' Bree', 'puff', 'abbit', 'gin', 'grim', ' Crunch', ' Loud']\n",
      "Value vec: Layer 12, index 1826\n",
      "['hire', ' stream', 'ume', ' saliva', 'buck', ' REPORT', 'riet', ' heap', 'bage', ' Stream']\n",
      "Value vec: Layer 19, index 2312\n",
      "[' scams', ' fraud', ' scam', ' hoax', ' spam', ' Fraud', ' bait', ' satire', ' troll', 'rape']\n",
      "Value vec: Layer 13, index 4065\n",
      "[' fuck', ' fucking', ' piss', ' goddamn', ' shit', ' godd', ' damned', ' damn', ' crap', ' shri']\n",
      "Value vec: Layer 12, index 3349\n",
      "[' heartbeat', ' irrit', ' skelet', 'gans', 'bians', ' tast', ' hungry', ' consume', ' flourish', ' obscure']\n",
      "Value vec: Layer 6, index 3972\n",
      "[' damn', ' fucking', ' hell', ' sinful', ' corrupt', ' immoral', ' independ', ' fuck', ' freedom', ' crap']\n",
      "Value vec: Layer 15, index 511\n",
      "[' booze', ' Nasa', ' billions', 'Engineers', ' millionaires', 'Britain', 'Scientists', ' burgers', 'billion', ' trillions']\n",
      "Value vec: Layer 16, index 603\n",
      "[' telev', '76561', ' Courtney', ' platinum', ' Slaughter', ' Lump', ' latt', ' nic', ' Icelandic', ' Spoon']\n",
      "Value vec: Layer 16, index 1741\n",
      "[' bland', ' bullshit', ' smug', ' arbitrarily', ' pointless', ' meaningless', ' nonsense', ' bogus', ' crap', ' gimm']\n",
      "Value vec: Layer 0, index 3752\n",
      "['tein', 'rial', ' Goo', 'riot', ' Tears', ' Reconstruction', ' WD', ' Ou', 'rehens', ' Desc']\n",
      "Value vec: Layer 11, index 3437\n",
      "[' arrog', ' unnecessarily', ' blatantly', ' falsely', ' inappropriately', ' disrespect', ' unacceptable', ' unnecessary', ' needless', ' artificially']\n",
      "Value vec: Layer 15, index 4051\n",
      "[' sexual', ' sex', ' nudity', ' sexuality', ' sexually', ' masturb', ' genital', ' penis', ' homosexuality', ' homosexual']\n",
      "Value vec: Layer 23, index 1672\n",
      "['oway', 'oland', 'ischer', 'rax', 'nesia', 'ook', ' OFF', 'ogg', 'roo', 'ink']\n",
      "Value vec: Layer 2, index 3998\n",
      "[' orphans', 'anoia', ' outnumbered', ' outsiders', ' dummy', '女', ' naked', ' clones', ' idiots', ' bast']\n",
      "Value vec: Layer 7, index 2494\n",
      "[' infertility', ' alien', ' inconsistency', ' omission', ' perpet', ' insanity', ' temptation', ' incest', ' contradiction', ' existence']\n",
      "Value vec: Layer 13, index 3620\n",
      "[' Frenchman', ' youngster', ' champ', ' Tex', ' superstar', ' pup', ' teenager', ' Spani', ' guy', ' veteran']\n",
      "Value vec: Layer 12, index 3413\n",
      "['tein', 'ococ', 'volent', 'folk', 'philis', ' underwear', 'WN', 'osphere', 'xual', 'thouse']\n",
      "Value vec: Layer 7, index 2018\n",
      "[' experien', 'swer', ' mathemat', 'ilee', ' skelet', 'elligence', 'PsyNetMessage', ' Grammy', ' lear', ' hamstring']\n",
      "Value vec: Layer 9, index 340\n",
      "[' nudity', ' slurs', ' sexuality', ' genital', ' chau', ' pregnant', ' liberation', ' sex', ' sexually', ' aloud']\n",
      "Value vec: Layer 9, index 2758\n",
      "[' Tex', ' Frog', ' reader', ' Spani', ' idiot', ' Eagle', ' minded', ' Swed', ' greedy', ' sucker']\n",
      "Value vec: Layer 13, index 3243\n",
      "['bed', ' Eps', 'cd', 'instein', 'enta', 'agy', ' bush', 'itas', 'ads', 'fb']\n",
      "Value vec: Layer 4, index 2335\n",
      "['uru', ' agric', 'software', 'unta', ' ec', 'nostic', 'oggles', ' detrim', 'unes', 'indust']\n",
      "Value vec: Layer 15, index 3116\n",
      "[' please', ' PLEASE', 'please', ' yours', ' yourselves', ' Please', ' THIS', ' ASAP', ' godd', 'xit']\n",
      "Value vec: Layer 0, index 3393\n",
      "[' sex', ' prostitutes', 'vag', ' sexual', ' lewd', ' genitals', ' prostitution', ' genital', ' breasts', ' underwear']\n",
      "Value vec: Layer 12, index 3094\n",
      "[' cuff', ' protr', ' wrists', ' neck', ' nipples', ' thigh', ' bones', ' ankles', ' legs', ' leg']\n",
      "Value vec: Layer 0, index 2723\n",
      "['iless', 'izens', ' crawling', 'iban', ' cov', ' raven', 'aciously', 'etheless', 'worms', 'ibus']\n",
      "Value vec: Layer 13, index 1916\n",
      "[' boobs', ' poop', ' shit', ' FUCK', ' shitty', ' crappy', 'shit', ' tits', ' freaking', ' stupid']\n",
      "Value vec: Layer 12, index 877\n",
      "[' darn', ' damn', ' boobs', ' fancy', ' REALLY', ' dudes', ' happened', ' Pretty', ' pissed', ' guess']\n",
      "Value vec: Layer 2, index 2935\n",
      "['aunder', 'volent', 'ighed', 'afety', 'ukemia', 'adesh', 'ahar', 'anguage', 'zinski', 'abad']\n",
      "Value vec: Layer 3, index 2765\n",
      "[' Lesbian', ' Osw', ' Patriot', ' Blues', ' Lena', 'ilege', ' Glob', ' Mam', ' blues', ' Machines']\n",
      "Value vec: Layer 6, index 2994\n",
      "[' dynam', 'yss', ' vic', ' anat', ' provision', ' def', 'ile', ' reserve', ' Gamb', 'wd']\n",
      "Value vec: Layer 9, index 3567\n",
      "[' disinformation', ' indoctr', ' propaganda', ' deception', ' Illuminati', ' backdoor', ' incest', ' fraudulent', ' propag', ' fals']\n",
      "Value vec: Layer 16, index 16\n",
      "[' breasts', ' bald', ' hair', ' boobs', ' beard', ' acne', ' nipples', ' Breast', ' mustache', ' erection']\n",
      "Value vec: Layer 17, index 3064\n",
      "['FK', 'pes', 'strings', 'end', 'tor', 'dds', 'ELS', 'hent', 'ELF', 'IDES']\n",
      "Value vec: Layer 19, index 505\n",
      "[' yes', ' ol', ' maybe', ' darn', ' yeah', ' wrink', ' frankly', ' uh', ' downright', ' dreaded']\n",
      "Value vec: Layer 2, index 122\n",
      "['zona', 'ukemia', 'romy', 'erella', 'ravis', 'iceps', ' nerves', ' vagina', 'issy', 'rogram']\n",
      "Value vec: Layer 5, index 4054\n",
      "['opt', 'ttes', 'odon', 'avia', 'ette', 'eus', 'lace', 'mire', 'punk', ' MEP']\n",
      "Value vec: Layer 4, index 144\n",
      "['作', ' bunk', ' spores', 'asus', ' nerve', ' unstable', ' transistor', ' avalanche', ' anth', ' Ion']\n",
      "Value vec: Layer 6, index 3121\n",
      "['ified', 'bite', 'ification', 'wood', 'cair', 'boy', 'iness', 'man', 'anium', ' fucking']\n",
      "Value vec: Layer 9, index 2540\n",
      "[' foul', ' negativity', ' pessimistic', ' overe', ' pseud', ' unacceptable', ' undermin', ' unnecess', ' wors', ' excessively']\n",
      "Value vec: Layer 9, index 2077\n",
      "['obbies', 'omon', ' miscon', 'LY', 'utes', '♥', ' Mono', '━', 'istine', 'Edited']\n",
      "Value vec: Layer 20, index 3123\n",
      "[' buff', ' nep', 'uple', ' virgin', ' intangible', 'nw', ' pharm', ' tamp', ' hosp', ' illiter']\n",
      "Value vec: Layer 12, index 2756\n",
      "[' burdens', ' bad', ' offending', ' horrible', ' imped', ' glare', ' terrible', ' negativity', ' horrendous', ' aversion']\n",
      "Value vec: Layer 20, index 551\n",
      "[' exiled', 'raped', ' crawl', 'esian', 'yll', ' aboriginal', 'alls', 'omach', ' cous', ' crawling']\n",
      "Value vec: Layer 7, index 3701\n",
      "[' Bash', 'worm', ' FAT', 'cake', 'worms', 'suit', ' Launcher', 'fuck', ' jer', 'hammer']\n",
      "Value vec: Layer 12, index 45\n",
      "[' acquies', ' guts', ' incompet', ' mishand', 'igr', ' capit', 'strate', ' behaving', ' coer', ' willingly']\n",
      "Value vec: Layer 10, index 3674\n",
      "[' merciless', 'utes', 'imeter', ' blazing', ' lapt', 'iform', 'aganda', 'thood', 'insula', 'ador']\n",
      "Value vec: Layer 8, index 273\n",
      "['wcs', ' Fiona', 'girlfriend', ' Aph', ' kissing', ' fiance', ' adultery', ' ejac', 'xual', ' kisses']\n",
      "Value vec: Layer 1, index 2057\n",
      "[' Bench', 'rodu', ' Brist', ' Sequ', ' Vers', ' Winchester', 'RIP', ' IP', ' Hit', ' Franco']\n",
      "Value vec: Layer 7, index 166\n",
      "[' IMAGES', ' reper', ' Celtic', 'okingly', ' humour', 'abo', ' stain', ' mosaic', ' slurs', 'otto']\n",
      "Value vec: Layer 4, index 3137\n",
      "[' Chem', ' Seraph', 'Tube', ' Raid', ' Rex', ' Ukrain', 'lic', ' Sinclair', ' Sov', ' Mint']\n",
      "Value vec: Layer 4, index 655\n",
      "[' skelet', 'lihood', 'terday', 'imilation', ' challeng', ' suprem', 'gdala', ' expectancy', ' deprivation', ' Celebr']\n",
      "Value vec: Layer 4, index 3494\n",
      "[' Souls', ' Moran', 'itor', 'assium', ' Sisters', ' Twins', 'hy', ' Dunn', ' Dent', ' Uncle']\n",
      "Value vec: Layer 14, index 883\n",
      "[' fuck', ' FUCK', 'HAHA', 'HAHAHAHA', ' hell', 'fuck', 'oooooooooooooooo', 'Fuck', ' wow', ' Fuck']\n",
      "Value vec: Layer 12, index 1587\n",
      "[' please', ' retweet', 'enegger', 'Congratulations', ' kindly', ' heed', 'assadors', 'emonic', ' sidx', 'netflix']\n",
      "Value vec: Layer 16, index 3941\n",
      "[' fuckin', ' godd', ' fuck', ' goddamn', ' dude', ' eh', ' ya', ' damn', ' uh', ' huh']\n",
      "Value vec: Layer 8, index 3745\n",
      "[' Bree', ' revolving', ' Hoo', ' dise', ' Dun', ' Kun', ' Cheong', 'uay', ' Ü', ' trough']\n",
      "Value vec: Layer 8, index 3066\n",
      "[' wasteful', ' mitochond', 'ahime', 'mentation', ' unnecess', ' Quantity', ' congestion', ' slowdown', ' reduction', ' bloated']\n",
      "Value vec: Layer 5, index 26\n",
      "['cedes', ' acron', 'BILITIES', 'escription', ' synergy', ' isEnabled', 'DEN', 'anu', 'bies', ' bung']\n",
      "Value vec: Layer 6, index 113\n",
      "[' tremend', ' Bastard', ' Complex', 'ritch', 'ovych', ' Runes', ' Peb', 'illac', ' metab', ' Winged']\n",
      "Value vec: Layer 11, index 339\n",
      "['龍喚士', ' Wad', ' lipstick', ' Mace', ' Kev', ' Doodle', ' Bottom', ' Scourge', ' Gaw', ' Kimber']\n",
      "Value vec: Layer 12, index 619\n",
      "[' Uriel', ' \"$:/', '||||', 'DEV', 'RAW', ' Supplementary', 'FUL', ' xx', 'IENT', ' Edited']\n",
      "Value vec: Layer 9, index 1028\n",
      "['ombo', ' Dak', ' Sapp', 'asta', 'lde', 'weet', ' Yugoslav', ' DAY', ' Pyr', 'ough']\n",
      "Value vec: Layer 6, index 3821\n",
      "[' Instruments', ' Instrument', 'cy', 'cies', ' stroke', ' instrument', 'Ap', ' Principle', ' offend', ' Cursed']\n",
      "Value vec: Layer 8, index 3310\n",
      "['STEM', 'forces', ' selves', ' bounty', ' reconcile', ' securely', ' bount', ' secret', ' jihad', ' force']\n",
      "Value vec: Layer 11, index 2776\n",
      "[' glim', ' desper', ' chicks', ' Incarn', ';;;;;;;;', 'Own', ' Sight', ' accur', 'ネ', ' Slave']\n"
     ]
    }
   ],
   "source": [
    "# Value vectors similar to probe\n",
    "k = 100\n",
    "norm = model.transformer.ln_f\n",
    "\n",
    "dot_prods = einsum(\"value_vecs d_model, d_model -> value_vecs\", norm(value_vectors), toxic_probe)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57926031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' cunt', 'fuck', 'Fuck', ' FUCK', ' fuck', ' Fuck', ' asshole', ' fucking', ' dick', ' whore']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(toxic_probe, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a395c",
   "metadata": {},
   "source": [
    "#### Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15eeb6ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/kebl6672/dpo-toxic-general/checkpoints/llama3_probe.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m toxic_probe \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m/data/kebl6672/dpo-toxic-general/checkpoints/llama3_probe.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m toxic_probe \u001b[39m=\u001b[39m toxic_probe\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(toxic_probe\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/data/kebl6672/miniconda3/envs/toxic/lib/python3.12/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m/data/kebl6672/miniconda3/envs/toxic/lib/python3.12/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    446\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/data/kebl6672/miniconda3/envs/toxic/lib/python3.12/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/kebl6672/dpo-toxic-general/checkpoints/llama3_probe.pt'"
     ]
    }
   ],
   "source": [
    "toxic_probe = torch.load(\"/data/kebl6672/dpo-toxic-general/checkpoints/llama3_probe.pt\")\n",
    "toxic_probe = toxic_probe.squeeze(0)\n",
    "print(toxic_probe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97540600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2f76a736a148e79ff208d87d3387bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e10e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([458752, 4096])\n"
     ]
    }
   ],
   "source": [
    "# Take the unembedding matrix\n",
    "token_embeds = model.lm_head.weight\n",
    "\n",
    "value_vectors = torch.cat(\n",
    "    [\n",
    "        model.model.layers[layer_idx].mlp.down_proj.weight.T\n",
    "        for layer_idx in range(model.config.num_hidden_layers)\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "print(value_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8455715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic token IDs: [71574, 41153, 99821]\n",
      "Non-toxic token IDs: [15339, 46593, 10931, 55225, 35184]\n"
     ]
    }
   ],
   "source": [
    "seed_token_toxic = [\"fuck\", \"shit\", \"crap\"]\n",
    "seed_token_non_toxic = [\"hello\", \"thanks\", \"friend\", \"peace\", \"welcome\"]\n",
    "\n",
    "toxic_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_toxic\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "non_toxic_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_non_toxic\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "print(\"Toxic token IDs:\", toxic_token_id)\n",
    "print(\"Non-toxic token IDs:\", non_toxic_token_id)\n",
    "\n",
    "toxic_embed = token_embeds[toxic_token_id].mean(dim=0)\n",
    "non_toxic_embed = token_embeds[non_toxic_token_id].mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f00ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unembed_to_text(vector, model, tokenizer, k=10):\n",
    "    norm = model.model.norm  \n",
    "    lm_head = model.lm_head.weight\n",
    "    dots = torch.einsum(\"vd,d->v\", lm_head, norm(vector))\n",
    "    top_k = dots.topk(k).indices\n",
    "    return tokenizer.batch_decode(top_k, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8d55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Value vec -> Layer 25, index 14065\n",
      "[' shit', ' crap', 'shit', 'crap', ' rubbish', ' garbage', ' bullshit', ' junk', ' nonsense', ' trash']\n",
      "Rank 2: Value vec -> Layer 18, index 15439\n",
      "[' fuck', 'Fuck', 'fuck', ' Fuck', ' fucks', ' fucked', ' fucking', ' FUCK', ' Fucking', ' shit']\n",
      "Rank 3: Value vec -> Layer 20, index 4492\n",
      "[' shit', ' fuck', 'Fuck', 'shit', ' fucked', 'fuck', ' Fuck', ' Fucking', ' fucks', ' assh']\n",
      "Rank 4: Value vec -> Layer 26, index 5705\n",
      "['arbon', '覚', 'anz', 'ihan', 'ород', '.getObject', 'oment', ' sadly', 'nist', 'asd']\n",
      "Rank 5: Value vec -> Layer 19, index 1569\n",
      "[' crap', ' shit', ' hell', ' living', ' Hell', 'living', ' tar', 'shit', 'crap', ' heck']\n",
      "Rank 6: Value vec -> Layer 19, index 7649\n",
      "[' stuff', ' shit', 'stuff', ' Stuff', 'Stuff', 'shit', '_stuff', ' fuck', ' guy', ' fucking']\n",
      "Rank 7: Value vec -> Layer 27, index 3863\n",
      "[' waste', ' Waste', ' trash', ' Trash', ' garbage', ' Junk', ' junk', 'Trash', 'trash', ' wastes']\n",
      "Rank 8: Value vec -> Layer 26, index 1086\n",
      "['Thank', ' Thank', 'thank', ' Persons', 'berman', 'Persons', 'ollen', 'roat', 'uitka', ' Uncomment']\n",
      "Rank 9: Value vec -> Layer 21, index 5982\n",
      "['�', 'eso', 'icular', 'adow', 'chsel', 'cheon', 'AO', ' Puppet', 'над', 'ipple']\n",
      "Rank 10: Value vec -> Layer 18, index 13797\n",
      "['Shoot', 'oh', ' shit', ' Shoot', ' crap', 'shit', ' swore', '_allocator', ' damn', 'OH']\n",
      "Rank 11: Value vec -> Layer 26, index 502\n",
      "['icker', '376', 'PropertyName', 'ogi', 'qe', '637', 'ardy', '497', 'erson', 'apt']\n",
      "Rank 12: Value vec -> Layer 16, index 9474\n",
      "['fft', 'дон', ' chorus', 'Courtesy', ':maj', 'emm', 'enz', 'orio', 'itag', 'ultz']\n",
      "Rank 13: Value vec -> Layer 21, index 11033\n",
      "['енні', ' Symphony', 'lez', 'atten', 'orts', 'anz', 'hic', ' Morrow', 'oler', 'uario']\n",
      "Rank 14: Value vec -> Layer 18, index 13381\n",
      "['�', 'gard', 'ippy', 'ồi', 'olon', 'عات', \" $('#'\", 'thon', '내기', 'ubits']\n",
      "Rank 15: Value vec -> Layer 27, index 8273\n",
      "[' thôi', 'наче', '_FILENO', 'roys', '근', 'hap', 'år', 'ło', 'aits', ' /*!<']\n",
      "Rank 16: Value vec -> Layer 22, index 2147\n",
      "['ony', 'erged', 'eno', 'eras', 'mtx', ' Ga', ' ripe', 'è', ' Lal', ' exported']\n",
      "Rank 17: Value vec -> Layer 21, index 10836\n",
      "[' stuff', ' Stuff', 'stuff', 'Stuff', '_stuff', ' things', ' thing', 'Things', ' Things', 'things']\n",
      "Rank 18: Value vec -> Layer 19, index 6041\n",
      "[' damn', ' shit', ' DAM', ' dam', ' fig', 'dam', 'damn', ' Damn', 'rat', ' crap']\n",
      "Rank 19: Value vec -> Layer 15, index 5014\n",
      "['κε', ' revolving', ' ', 'ecided', 'REC', 'sta', '_DIFF', 'locker', ' rel', 'lue']\n",
      "Rank 20: Value vec -> Layer 27, index 7094\n",
      "['c', 'cy', 'cin', 'cu', 'cq', 'ci', 'cus', 'cj', 'cw', 'cil']\n"
     ]
    }
   ],
   "source": [
    "# Value vectors similar to embedding difference\n",
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "target_vec = toxic_embed - non_toxic_embed\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), target_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "print\n",
    "for rank, vec_idx in enumerate(top_value_vecs):\n",
    "    layer = vec_idx.item() // (4096*4)\n",
    "    index = vec_idx.item() % (4096*4)\n",
    "    \n",
    "    print(f\"Rank {rank + 1}: Value vec -> Layer {layer}, index {index}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b33e3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shit', 'crap', 'fuck', ' shit', 'Fuck', ' fuck', ' Fuck', ' crap', ' FUCK', ' fucked']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(target_vec, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b118125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 23, index 1711\n",
      "['iri', 'abb', ' Kv', 'regor', ' hät', 'engkap', 'ORAGE', '_ABI', 'ABB', 'ریم']\n",
      "Value vec: Layer 59, index 1168\n",
      "['�', ' Toll', 'omap', 'ướ', 'erva', 'agu', 'ertime', ' Zucker', 'ijn', 'ulet']\n",
      "Value vec: Layer 20, index 2041\n",
      "[' Nass', '�', 'hof', 'eyen', ' CSRF', ' WithEvents', 'chip', ' NaN', 'shiv', 'öh']\n",
      "Value vec: Layer 19, index 1362\n",
      "['ante', 'aire', 'że', ' حص', 'prü', 'ska', 'furt', 'sing', 'asu', 'wicklung']\n",
      "Value vec: Layer 12, index 124\n",
      "['oom', 'bine', 'alion', 'mamak', 'erne', ' Leer', '.Apis', 'atat', '润', 'prung']\n",
      "Value vec: Layer 24, index 3463\n",
      "[' Schro', '�', 'oop', 'sch', 'et', ' Frog', ' Pee', '_pitch', 'createClass', '\\\\r']\n",
      "Value vec: Layer 61, index 2123\n",
      "[' luck', ' fortunes', ' Prob', 'luck', ' blow', 'éo', ' dam', 'unu', ' Blow', ' fortune']\n",
      "Value vec: Layer 84, index 3827\n",
      "['angep', 'enco', ' mer', ' Blake', 'ToPoint', ' Committee', ' proof', 'mn', '_ped', ' Mer']\n",
      "Value vec: Layer 25, index 52\n",
      "['apis', 'oenix', 'kal', 'idel', '-fetch', 'alian', 'JJ', 'rado', 'рай', 'anon']\n",
      "Value vec: Layer 27, index 1791\n",
      "['mile', 'nore', 'acre', 'SEG', ' Barton', 'eree', 'agar', '�', 'Reporter', 'lung']\n",
      "Value vec: Layer 76, index 2511\n",
      "['alis', 'adro', ' consolid', 'iyet', 'ekli', ' Chase', 'uel', '.Selection', 'لیس', 'crud']\n",
      "Value vec: Layer 75, index 782\n",
      "['pline', 'uran', '卷', 'ть', 'arith', 'ckt', 'vise', 'refix', '对方', 'ioso']\n",
      "Value vec: Layer 7, index 2196\n",
      "['ustil', 'ysis', 'PTION', ' bow', ' meis', ' Hose', 'LAS', ' Lug', 'FileVersion', ' coco']\n",
      "Value vec: Layer 106, index 3624\n",
      "['ryn', 'rys', 'kili', 'APER', 'corp', 'ery', ' Ves', 'eworld', 'ちょ', 'positions']\n",
      "Value vec: Layer 46, index 3858\n",
      "['igon', '.osgi', 'emez', '_GF', 'adio', 'eyen', 'okud', ' Dalton', ' Spice', 'importe']\n",
      "Value vec: Layer 35, index 2373\n",
      "['iband', '周', 'ixin', 'арч', ' Tart', 'δέ', 'iad', ' Fab', 'την', 'COMPARE']\n",
      "Value vec: Layer 52, index 3598\n",
      "['운데', 'ayer', 'imizer', ' nominal', ' Hayward', 'dera', ' Primary', 'away', '.viewer', ' en']\n",
      "Value vec: Layer 78, index 3425\n",
      "['ayah', 'hee', ' же', 'allis', ' Spoon', '�', 'rane', 'tables', 'ihu', ' propTypes']\n",
      "Value vec: Layer 56, index 1797\n",
      "['ambre', 'qua', 'Badge', 'Floor', 'くだ', 'stadt', 'μία', 'مان', 'قی', '713']\n",
      "Value vec: Layer 80, index 2540\n",
      "['inary', 'inaire', 'čil', 'cth', 'oose', '-fw', '爵', 'lest', 'ナル', 'adem']\n",
      "Value vec: Layer 7, index 3376\n",
      "[' verm', 'monic', 'оже', 'enic', '.semantic', 'фра', 'auc', 'agini', ' Broadcast', 'ToSend']\n",
      "Value vec: Layer 47, index 2306\n",
      "['มอ', 'landers', 'хран', ' Maher', 'arm', 'NTAX', '험', 'amen', 'ieee', 'ivers']\n",
      "Value vec: Layer 32, index 1989\n",
      "['泛', '-INF', 'rada', '�', 'idon', 'YST', '_SWITCH', '.addTab', 'گل', 'edback']\n",
      "Value vec: Layer 4, index 2198\n",
      "['anno', ' Rip', 'ンチ', 'ク', 'prav', 'meth', 'asha', ' výbě', 'rix', ' Ange']\n",
      "Value vec: Layer 96, index 1848\n",
      "['ours', 'ewire', '勤', 'irst', 'Songs', 'xz', 'pei', 'radient', 'hurst', 'نگی']\n",
      "Value vec: Layer 68, index 3675\n",
      "['�', '.userInteractionEnabled', 'signal', 'opia', 'enin', ' Brut', '965', 'irate', ' behalf', 'lay']\n",
      "Value vec: Layer 42, index 1362\n",
      "['оро', 'owler', ' Matchers', 'ória', 'ledon', 'recision', 'viar', 'rier', 'クリ', 'ρθ']\n",
      "Value vec: Layer 73, index 1306\n",
      "['IFO', 'tf', 'kenin', '・・・\\n\\n', 'immel', 'spl', 'iggins', '.appspot', 'esterday', 'TF']\n",
      "Value vec: Layer 95, index 3811\n",
      "[' mode', ' Mode', 'mode', 'Mode', '-mode', '_mode', ' modes', '.mode', ' MODE', '_MODE']\n",
      "Value vec: Layer 17, index 697\n",
      "['牌', 'ftime', 'جان', 'гал', 'tero', 'thon', 'anela', 'nev', '庭', '陶']\n"
     ]
    }
   ],
   "source": [
    "# Value vectors similar to probe\n",
    "k = 30\n",
    "norm = model.model.norm  \n",
    "\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), toxic_probe)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // 4096}, index {vec_idx % 4096}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fcf645c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kommen', ' FUCK', 'ển', 'iyah', '̆', 'dirty', '털', 'fuck', ' Rudd', ' Кра']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(toxic_probe, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b762ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(target_vec, '/data/kebl6672/dpo-toxic-general/checkpoints/llama3_toxic_embed.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f218a5",
   "metadata": {},
   "source": [
    "#### Gemma-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7760fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2304])\n"
     ]
    }
   ],
   "source": [
    "toxic_probe = torch.load(\"/data/kebl6672/dpo-toxic-general/checkpoints/gemma2_2b_probe.pt\")\n",
    "toxic_probe = toxic_probe.squeeze(0)\n",
    "print(toxic_probe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42b484f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cd09bfa0624a7699f50fd5a4f5303d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2-2b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8969f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239616, 2304])\n"
     ]
    }
   ],
   "source": [
    "# Take the unembedding matrix\n",
    "token_embeds = model.lm_head.weight\n",
    "\n",
    "value_vectors = torch.cat(\n",
    "    [\n",
    "        model.model.layers[layer_idx].mlp.down_proj.weight.T\n",
    "        for layer_idx in range(model.config.num_hidden_layers)\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "print(value_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00d85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic token IDs: [34024, 31947, 101886]\n",
      "Non-toxic token IDs: [17534, 12203, 9141, 44209, 28583]\n"
     ]
    }
   ],
   "source": [
    "seed_token_toxic = [\"fuck\", \"shit\", \"crap\"]\n",
    "seed_token_non_toxic = [\"hello\", \"thanks\", \"friend\", \"peace\", \"welcome\"]\n",
    "\n",
    "toxic_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_toxic\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "non_toxic_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_non_toxic\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "print(\"Toxic token IDs:\", toxic_token_id)\n",
    "print(\"Non-toxic token IDs:\", non_toxic_token_id)\n",
    "\n",
    "toxic_embed = token_embeds[toxic_token_id].mean(dim=0)\n",
    "non_toxic_embed = token_embeds[non_toxic_token_id].mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce896aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unembed_to_text(vector, model, tokenizer, k=10):\n",
    "    norm = model.model.norm  \n",
    "    lm_head = model.lm_head.weight\n",
    "    dots = torch.einsum(\"vd,d->v\", lm_head, norm(vector))\n",
    "    top_k = dots.topk(k).indices\n",
    "    return tokenizer.batch_decode(top_k, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54377428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 21, index 8804\n",
      "['HSSF', 'sptr', ' umge', ' siihen', '例句', ' advoc', 'Computed', ' riten', 'subpackage', 'glieder']\n",
      "Value vec: Layer 3, index 4727\n",
      "[' shit', ' Shit', 'shit', 'Shit', ' SHIT', ' crap', ' shits', 'Crap', ' shite', ' shitty']\n",
      "Value vec: Layer 19, index 7297\n",
      "['esModule', 'migrationBuilder', 'celot', ' pinulongan', 'RectangleBorder', 'hoeddwyd', 'oa̍t', 'WireFormatLite', ' fourrure', 'fillType']\n",
      "Value vec: Layer 19, index 8366\n",
      "[' dudes', ' dude', ' stuff', ' guys', ' kinda', ' shit', ' guy', ' crap', ' thingy', ' hella']\n",
      "Value vec: Layer 23, index 7107\n",
      "[' fuck', ' fucks', ' fucking', ' fucked', ' shit', 'fuck', 'Fuck', ' Fucking', 'fucking', 'Fucking']\n",
      "Value vec: Layer 25, index 4751\n",
      "['convertView', 'NavController', 'ClassNotFound', 'cellulose', ' defaultstate', ' Chuk', ' Vikipedi', 'queryInterface', 'دانشنامهٔ', ' PopupWindow']\n",
      "Value vec: Layer 19, index 1704\n",
      "['ValueStyle', 'GenerationType', 'BeginContext', 'InjectAttribute', ' мәкал', 'enumi', 'IntoConstraints', 'AnchorTagHelper', 'ValueGeneration', 'Personensuche']\n",
      "Value vec: Layer 11, index 3962\n",
      "[' goddamn', 'fucking', ' fucking', 'FUCK', 'fuck', ' FUCKING', ' Fucking', ' fuckin', ' fucked', 'Fuck']\n",
      "Value vec: Layer 4, index 2288\n",
      "[' idiot', ' bastard', ' asshole', ' bastards', ' assholes', ' idiots', ' fucks', 'fucker', ' moron', 'FUCK']\n",
      "Value vec: Layer 17, index 3081\n",
      "[' worse', ' worst', ' horrible', 'Worse', ' Worse', ' terrible', ' disastrous', ' Worst', 'Worst', ' horribly']\n",
      "Value vec: Layer 0, index 5956\n",
      "[' myſelf', ' itſelf', ' Efq', 'ſelf', ' ―――――', ' Monfieur', ' Jefus', ' Majefty', ' pleaſure', ' doubtnut']\n",
      "Value vec: Layer 6, index 5539\n",
      "['contentValues', 'WriteLiteral', 'stoff', ' Beverage', 'otheby', ' alimentaire', ' aeron', ' feeds', ' quanti', 'APON']\n",
      "Value vec: Layer 20, index 7196\n",
      "['mybatisplus', ' BoxDecoration', ' AssemblyTitle', ' Sima', 'masing', 'ГЛА', 'wicks', ' Juno', ' Nich', 'GEBURTS']\n",
      "Value vec: Layer 20, index 4408\n",
      "[' виправивши', ' Roskov', 'afficheront', 'SourceChecksum', 'GEBURTSDATUM', 'sizeCache', 'SerializedName', 'urlpatterns', '脚注の使い方', '########.']\n",
      "Value vec: Layer 19, index 4273\n",
      "[' evil', ' poison', ' Satan', ' dirty', ' contamination', 'rror', ' contamin', ' toxic', 'poison', 'Satan']\n",
      "Value vec: Layer 17, index 5484\n",
      "[' poitrine', ' ră', 'Tob', 'Pon', 'tably', ' voce', ' Cæsar', 'import', ' cref', 'rop']\n",
      "Value vec: Layer 5, index 8551\n",
      "['(++', 'ROLS', 'unately', ' (++', 'UTTON', ' Ums', ' incessantly', ' convaincre', 'POUND', 'uffe']\n",
      "Value vec: Layer 7, index 3666\n",
      "[' insanely', ' insane', ' absolutely', ' incredibly', ' utterly', ' ridiculous', ' fucking', ' hideous', ' unbelievably', ' shit']\n",
      "Value vec: Layer 6, index 5138\n",
      "[\" '\\\\\\\\;'\", ' @{', 'FontStyle', ' الرياضيه', ' judiciaire', 'ंदीखरीदारी', 'aarrggbb', 'DeleteBehavior', 'Personensuche', ' transfieras']\n",
      "Value vec: Layer 6, index 1934\n",
      "[' NSError', ' worse', 'worse', ' Hurts', ' Worse', 'JSONException', 'NSError', ' fouling', ' severity', ' mismanagement']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "target_vec = toxic_embed - non_toxic_embed\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), target_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "# print(top_value_vecs)\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // (2304*4)}, index {vec_idx % (2304*4)}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "584d41d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shit', ' shit', 'fuck', 'Shit', ' SHIT', 'crap', ' Shit', ' fuck', ' crap', ' Fuck']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(target_vec, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ce985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Value vec -> Layer 4, index 2288\n",
      "[' idiot', ' bastard', ' asshole', ' bastards', ' assholes', ' idiots', ' fucks', 'fucker', ' moron', 'FUCK']\n",
      "Rank 2: Value vec -> Layer 5, index 5083\n",
      "['amssymb', 'ResponseWriter', ' autorytatywna', '}\".', '://$', ' państw', 'Tienen', 'pédie', 'ác', 'Datuak']\n",
      "Rank 3: Value vec -> Layer 7, index 3280\n",
      "[' prochaines', ' như', 'лия', ' Organ', ' durer', ' crown', ' pengh', '!(\"{}\",', 'organ', 'uidado']\n",
      "Rank 4: Value vec -> Layer 1, index 3962\n",
      "[' ());', '/}.', '--)\\r', '。）', \"']))\\r\", 'AndEndTag', ' }}}', \"']);\\r\", '}\")\\r', \"'},\\r\"]\n",
      "Rank 5: Value vec -> Layer 15, index 3635\n",
      "['Décès', ' мәкал', 'MemoryWarning', 'findpost', ' iprot', 'mobileqq', 'Demografia', 'CloseOperation', 'paramref', ']++;']\n",
      "Rank 6: Value vec -> Layer 21, index 9207\n",
      "[' depicted', ' represented', ' portrayed', ' featured', ' pictured', ' profiled', ' interviewed', ' showcased', ' analyzed', ' examined']\n",
      "Rank 7: Value vec -> Layer 3, index 8070\n",
      "['rungsseite', 'posedge', '########.', 'tagHelperRunner', 'expandindo', '+#+#', \" '\\\\\\\\;'\", 'principalTable', 'RUnlock', ' tartalomajánló']\n",
      "Rank 8: Value vec -> Layer 6, index 2476\n",
      "[' similar', ' move', 'HomeController', 'íslu', '早く', ' do', 'Move', ' Move', 'SpringBootTest', ' moving']\n",
      "Rank 9: Value vec -> Layer 22, index 4165\n",
      "['Ữ', ' anser', ' gus', ' luy', 'enegger', 'Rush', ' Lester', ' Foundry', 'Lester', '≺']\n",
      "Rank 10: Value vec -> Layer 18, index 2597\n",
      "[' yes', ' ridiculous', ' StatelessWidget', ' Yes', ' absurd', 'Yes', ' ludicrous', ' pathetic', 'endwhile', ' awful']\n",
      "Rank 11: Value vec -> Layer 17, index 5506\n",
      "['TagHelper', 'protoimpl', ' ReactDOM', ' typelib', 'ArrowToggle', '#+#', ' препратки', ' gainera', ' Мексичка', 'TypeConverter']\n",
      "Rank 12: Value vec -> Layer 5, index 4757\n",
      "[' EconPapers', 'AndEndTag', 'AddHtmlAttribute', 'InSection', ' ©️', 'ViewImports', '\\ufeff#', 'TagMode', 'гӀ', 'قایناقلار']\n",
      "Rank 13: Value vec -> Layer 7, index 9157\n",
      "['########.', ' initWithFrame', ' clogging', ' дописавши', ' cleanliness', 'WebServlet', 'ագրություններ', '存于互联网档案馆', '__;', ' fouling']\n",
      "Rank 14: Value vec -> Layer 16, index 1468\n",
      "['OGND', ' GetEnumerator', ' contextLoads', '\\ufeff//', ' الدولى', 'Geplaatst', 'Personensuche', ' getchar', ' Bourgoin', ' للمعارف']\n",
      "Rank 15: Value vec -> Layer 1, index 8886\n",
      "[' myſelf', ' itſelf', ' Efq', ' Monfieur', ' Theſe', ' themſelves', ' Majefty', ' Jefus', ' Anſ', 'ſelf']\n",
      "Rank 16: Value vec -> Layer 18, index 2902\n",
      "[' String', 'toString', 'String', 'evos', ' string', 'str', 'ToString', ' str', ' }^{[', ' Strings']\n",
      "Rank 17: Value vec -> Layer 21, index 5661\n",
      "[' particular', ' certain', 'particular', ' specific', 'certain', ' Particular', ' Certain', 'Certain', ' PARTICULAR', 'Particular']\n",
      "Rank 18: Value vec -> Layer 1, index 8498\n",
      "[' betweenstory', 'HasAnnotation', ' ligiloj', 'TintMode', ' Exactos', 'رشف', ' Administrativna', 'lankton', ' ProtoMessage', 'ьаж']\n",
      "Rank 19: Value vec -> Layer 3, index 8742\n",
      "[' ویکی\\u200cپدیای', 'fjspx', 'èdia', '\".\\r', 'ueuse', 'EnableWeb', \"]-'\", '...\\r', ' amorosa', ' ***/']\n",
      "Rank 20: Value vec -> Layer 6, index 3007\n",
      "['Искәрмәләр', ' VICE', 'bootstrapcdn', ' tumblr', 'ngdoc', 'iços', ' estimés', 'saraba', 'GTCX', ' Polyp']\n",
      "Rank 21: Value vec -> Layer 3, index 3261\n",
      "['IntoConstraints', 'mybatisplus', 'sidemargin', 'AlterField', 'fromnode', '\\ufeff#', 'IsMutable', 'StringCopy', 'AddHtmlAttribute', 'ốn']\n",
      "Rank 22: Value vec -> Layer 3, index 4727\n",
      "[' shit', ' Shit', 'shit', 'Shit', ' SHIT', ' crap', ' shits', 'Crap', ' shite', ' shitty']\n",
      "Rank 23: Value vec -> Layer 15, index 3003\n",
      "['AndEndTag', 'protoimpl', ' maravilloso', 'enumii', 'StoreMessageInfo', 'లాలు', ' Füßen', ' medlemmer', ' ritratto', ' استنادى']\n",
      "Rank 24: Value vec -> Layer 17, index 7018\n",
      "[' area', ' region', ' era', ' period', 'area', ' يتيمه', ' région', ' situation', ' região', '时代']\n",
      "Rank 25: Value vec -> Layer 15, index 8094\n",
      "['ⓘ', 'ServletRequest', ' colar', ' cucharadas', 'foreignKey', 'oOo', ' Fla', 'IMIENTO', ' \"', 'Ó']\n",
      "Rank 26: Value vec -> Layer 17, index 6911\n",
      "[' replaced', 'replaced', ' replace', ' replacement', ' Replaced', ' Replace', ' Replacement', 'replacement', 'Replace', ' replaces']\n",
      "Rank 27: Value vec -> Layer 9, index 2351\n",
      "[' صوتيه', 'ArrowToggle', ']\")]', '发表于', ' ویکی\\u200cپدیا', ' ActionResult', 'WriteLiteral', ' endwhile', 'DockStyle', 'TabIndex']\n",
      "Rank 28: Value vec -> Layer 24, index 7991\n",
      "['anti', 'casian', ' anti', 'findpost', 'tagHelperRunner', 'er', 'worthiness', ' woning', 'Pio', 'APORE']\n",
      "Rank 29: Value vec -> Layer 10, index 7039\n",
      "['FailureListener', ' onCancelled', ' NSError', ' onFailure', 'saraba', ' waste', ' ato', ' insecure', ' الوطنيه', ' strto']\n",
      "Rank 30: Value vec -> Layer 9, index 6593\n",
      "['findpost', 'principalTable', 'izr', 'IBOutlet', 'AlterField', ' >=\",', '>//', 'offsetof', 'sizeCache', 'ficie']\n",
      "Rank 31: Value vec -> Layer 4, index 1804\n",
      "['Clik', 'RenderAtEndOf', 'ruptedException', 'GEBURTSDATUM', \" __('\", ' ‘', '\"\"\"', ' jLabel', \" '\", 'нома']\n",
      "Rank 32: Value vec -> Layer 23, index 7586\n",
      "['+:+', 'rungsseite', ' للمعارف', 'AndEndTag', 'ocino', ' juveniles', ' docent', '</thead>', ' ویکی\\u200cپدیای', ' salaried']\n",
      "Rank 33: Value vec -> Layer 4, index 5518\n",
      "[' rich', ' riche', ' Wealth', ' wealth', 'wealth', ' richest', ' wealthy', 'rich', 'Rich', ' riches']\n",
      "Rank 34: Value vec -> Layer 23, index 675\n",
      "['Density', 'MEMORANDUM', 'kpi', ' Density', 'chong', ' actionMode', 'CppCodeGen', 'DropColumn', 'uxxxx', ' novios']\n",
      "Rank 35: Value vec -> Layer 15, index 2734\n",
      "[' Réponses', 'FormTagHelper', 'ErrUnexpectedEOF', 'LabelTagHelper', 'StateToProps', ' ExecuteAsync', 'сылкі', 'évaluateur', ' AppColors', 'migrationBuilder']\n",
      "Rank 36: Value vec -> Layer 25, index 8495\n",
      "[' parts', 'parts', ' PARTS', ' Parts', 'Parts', 'PARTS', ' pieces', ' Pieces', ' bits', ' Teile']\n",
      "Rank 37: Value vec -> Layer 2, index 3129\n",
      "[' withRouter', 'doctype', 'enumi', 'SourceChecksum', ' resourceCulture', ' Majesté', 'DOCTYPE', '談社', ' \"<?', 'Personendaten']\n",
      "Rank 38: Value vec -> Layer 16, index 2944\n",
      "['GEBURTSDATUM', 'Билгалдахарш', '__*/', 'AndEndTag', ' nahilalakip', ' CreateTagHelper', \" '\\\\\\\\;'\", ' незавершена', ' ویکی\\u200cپدی', 'CppMethod']\n",
      "Rank 39: Value vec -> Layer 11, index 8015\n",
      "['tagHelperRunner', ' betweenstory', ' ModelExpression', 'AddTagHelper', ' defaultstate', ' SafeMath', 'uxxxx', ' propOrder', 'IUrlHelper', 'TagMode']\n",
      "Rank 40: Value vec -> Layer 9, index 897\n",
      "['NameInMap', 'webElementXpaths', 'complexType', ' CreateTagHelper', '})`', \"'][$\", ' endforeach', 'jsxFileName', 'MemoryWarning', 'kuit']\n",
      "Rank 41: Value vec -> Layer 4, index 1619\n",
      "['########.', 'toir', 'titleMargin', 'mobileqq', 'صدار', ' hâte', ' nakalista', 'CardContent', ' OnInit', ' Wikimédia']\n",
      "Rank 42: Value vec -> Layer 16, index 9029\n",
      "[' оригіналу', 'awtextra', ' دیکھیے', 'MigrationBuilder', ' لينك', ' commission', 'BeforeMethod', ' InputDecoration', ' dessus', 'styleable']\n",
      "Rank 43: Value vec -> Layer 22, index 4810\n",
      "[' after', 'after', ' After', ' aft', 'After', ' после', ' AFTER', ' efter', ' بعد', ' nach']\n",
      "Rank 44: Value vec -> Layer 25, index 4129\n",
      "['providedIn', ' AssemblyCulture', 'AnchorTagHelper', 'hlung', '<?>>', 'segno', 'caloosa', '弈', ' studio', ' studios']\n",
      "Rank 45: Value vec -> Layer 15, index 2072\n",
      "['AZIONE', 'cussion', 'abatic', 'Barton', 'goin', ' Hano', 'jaan', 'arithmic', 'ρίες', ' Sita']\n",
      "Rank 46: Value vec -> Layer 22, index 9162\n",
      "[' autorytatywna', '+:+', 'EndGlobalSection', 'webElementXpaths', 'PMailer', 'AutoScaleMode', 'GenerationType', '(!__', 'WriteTagHelper', 'ResumeLayout']\n",
      "Rank 47: Value vec -> Layer 12, index 1218\n",
      "[' EconPapers', ' resourceCulture', 'ResumeLayout', 'IUrlHelper', 'Ծանոթ', 'titudine', 'IfNeeded', 'DispatchToProps', 'PUTY', 'Externé']\n",
      "Rank 48: Value vec -> Layer 3, index 7175\n",
      "['ener', 'ment', 'tic', ' plati', 'Mientras', ' CURIAM', ' Mientras', '\">&', 'while', 'haa']\n",
      "Rank 49: Value vec -> Layer 11, index 4228\n",
      "['-------\\x0c', 'MessageTagHelper', ' autorytatywna', '为例', \"::_('\", 'setAccessible', ' combineReducers', 'cydow', 'actionMode', 'Caution']\n",
      "Rank 50: Value vec -> Layer 10, index 3875\n",
      "['@', '<blockquote>', 'co', 'gettext', ' au', 'hv', 'º', ' tri', ' calloc', ' ăn']\n"
     ]
    }
   ],
   "source": [
    "# Value vectors similar to probe\n",
    "k = 50\n",
    "norm = model.model.norm  \n",
    "\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), toxic_probe)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "top_scores = dot_prods[top_value_vecs]\n",
    "\n",
    "print\n",
    "for rank, vec_idx in enumerate(top_value_vecs):\n",
    "    layer = vec_idx.item() // (2304*4)\n",
    "    index = vec_idx.item() % (2304*4)\n",
    "    \n",
    "    print(f\"Rank {rank + 1}: Value vec -> Layer {layer}, index {index}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d8b6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rungsseite', 'fuck', 'Fucking', 'انيف', 'AndEndTag', 'expandindo', ' asshole', ' Fuck', ' fucking', 'IntoConstraints']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(toxic_probe, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55633fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(target_vec, 'gemma2_toxic_embed.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7a227",
   "metadata": {},
   "source": [
    "#### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cabdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "toxic_probe = torch.load(\"/data/kebl6672/dpo-toxic-general/checkpoints/mistral_probe.pt\")\n",
    "toxic_probe = toxic_probe.squeeze(0)\n",
    "print(toxic_probe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d98b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d6a9b6934d4778a8e192331eae302f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b6ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([458752, 4096])\n"
     ]
    }
   ],
   "source": [
    "# Take the unembedding matrix\n",
    "token_embeds = model.lm_head.weight\n",
    "\n",
    "value_vectors = torch.cat(\n",
    "    [\n",
    "        model.model.layers[layer_idx].mlp.down_proj.weight.T\n",
    "        for layer_idx in range(model.config.num_hidden_layers)\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "print(value_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bc2861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic token IDs: [4159, 5492, 21849]\n",
      "Non-toxic token IDs: [8196, 1832, 6405, 10058]\n"
     ]
    }
   ],
   "source": [
    "seed_token_toxic = [\"fuck\", \"shit\", \"crap\"]\n",
    "seed_token_non_toxic = [\"hello\", \"thanks\", \"friend\", \"peace\", \"welcome\"]\n",
    "\n",
    "toxic_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_toxic\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "non_toxic_token_id = [\n",
    "    tokenizer(tok, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    for tok in seed_token_non_toxic\n",
    "    if len(tokenizer(tok, add_special_tokens=False)[\"input_ids\"]) == 1\n",
    "]\n",
    "\n",
    "print(\"Toxic token IDs:\", toxic_token_id)\n",
    "print(\"Non-toxic token IDs:\", non_toxic_token_id)\n",
    "\n",
    "toxic_embed = token_embeds[toxic_token_id].mean(dim=0)\n",
    "non_toxic_embed = token_embeds[non_toxic_token_id].mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda670d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unembed_to_text(vector, model, tokenizer, k=10):\n",
    "    norm = model.model.norm  \n",
    "    lm_head = model.lm_head.weight\n",
    "    dots = torch.einsum(\"vd,d->v\", lm_head, norm(vector))\n",
    "    top_k = dots.topk(k).indices\n",
    "    return tokenizer.batch_decode(top_k, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9714355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value vec: Layer 22, index 1061\n",
      "['fuck', 'fucking', 'Fuck', 'fucked', 'shit', 'shit', 'bullshit', 'asshole', 'shitty', 'assh']\n",
      "Value vec: Layer 22, index 15900\n",
      "['screw', 'fuck', 'Fuck', 'fucked', 'Scre', 'fucking', 'shit', 'shit', 'bullshit', 'piss']\n",
      "Value vec: Layer 19, index 4689\n",
      "['crap', 'shit', 'damn', 'shit', 'damned', 'hell', 'bitch', 'piss', 'Hell', 'fuck']\n",
      "Value vec: Layer 22, index 9629\n",
      "['squ', 'jack', 'shit', 'crap', 'Jack', 'shit', 'dick', 'jack', 'zip', 'Jack']\n",
      "Value vec: Layer 19, index 6318\n",
      "['dude', 'kinda', 'crap', 'shit', 'gotta', 'freak', 'ain', 'guy', 'guys', 'awesome']\n",
      "Value vec: Layer 19, index 7269\n",
      "['shit', 'crap', 'shit', 'freak', 'flip', 'melt', 'hell', 'reak', 'Hell', 'igg']\n",
      "Value vec: Layer 18, index 10976\n",
      "['oen', 'ysk', 'enth', 'ган', '/******/', 'ți', 'alf', 'Sever', 'alias', 'consent']\n",
      "Value vec: Layer 22, index 5047\n",
      "['shit', '****', 'shit', '***', '**', 'fucking', 'Fuck', '******', '***', '**']\n",
      "Value vec: Layer 25, index 8070\n",
      "['reen', 'furt', 'ague', 'sha', 'chaft', 'ví', '�', 'Za', 'dale', 'emi']\n",
      "Value vec: Layer 18, index 2787\n",
      "['stupid', 'crap', 'nonsense', 'bullshit', 'assh', 'shit', 'foolish', 'idiot', 'garbage', 'asshole']\n",
      "Value vec: Layer 26, index 10726\n",
      "['alis', 'ieg', 'amos', 'ча', 'gebra', 'agine', 'virt', 'eing', 'iw', 'geon']\n",
      "Value vec: Layer 17, index 8050\n",
      "['sex', 'sexual', 'penis', 'Sex', 'porn', 'sex', 'mast', 'dick', 'fuck', 'Fuck']\n",
      "Value vec: Layer 22, index 9770\n",
      "['/*!', 'atte', '�', 'соб', 'ahan', 'ierto', 'LT', 'зан', 'chaft', '장']\n",
      "Value vec: Layer 20, index 4489\n",
      "['fe', 'fa', 'po', 'dro', 'shit', 'Fa', 'crap', 'ex', 'waste', 'Po']\n",
      "Value vec: Layer 24, index 2485\n",
      "['stuff', 'stuffed', 'crap', 'shit', 'uff', 'shit', '东', 'nonsense', 'uffs', 'staff']\n",
      "Value vec: Layer 20, index 5499\n",
      "['bull', 'Bull', 'BS', 'BS', 'bullshit', 'crap', 'ull', 'bs', 'hors', 'garbage']\n",
      "Value vec: Layer 27, index 10147\n",
      "['foul', 'corrupt', 'mal', 'dirty', 'fraud', 'abuse', 'corruption', 'dirty', 'evil', 'poison']\n",
      "Value vec: Layer 21, index 4797\n",
      "['stuff', 'crap', 'shit', 'junk', 'shit', 'ST', 'UNK', 'stuffed', 'bunk', 'unk']\n",
      "Value vec: Layer 17, index 6981\n",
      "['damn', 'damned', 'fucking', 'bloody', 'freak', 'god', 'dam', 'Fuck', 'Dam', 'Dam']\n",
      "Value vec: Layer 26, index 5792\n",
      "['ANK', 'ank', 'due', 'gr', 'due', 'illo', 'luck', 'Due', 'aid', 'fort']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "norm = model.model.norm  \n",
    "\n",
    "target_vec = toxic_embed - non_toxic_embed\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), target_vec)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "\n",
    "for vec_idx in top_value_vecs:\n",
    "    print(f\"Value vec: Layer {vec_idx // (4096*4)}, index {vec_idx % (4096*4)}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f76ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shit', 'crap', 'fuck', 'shit', 'Fuck', 'fucked', 'fucking', 'bullshit', 'shitty', 'piss']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(target_vec, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(target_vec, 'mistral_toxic_embed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af164f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Value vec -> Layer 22, index 1061\n",
      "['fuck', 'fucking', 'Fuck', 'fucked', 'shit', 'shit', 'bullshit', 'asshole', 'shitty', 'assh']\n",
      "Rank 2: Value vec -> Layer 2, index 8896\n",
      "['jav', 'olic', 'uler', 'witness', 'cav', '@@', 'pez', '�', 'idiot', 'bear']\n",
      "Rank 3: Value vec -> Layer 14, index 2292\n",
      "['shit', 'crap', 'damn', 'fucking', 'shit', 'fuck', 'shitty', 'bullshit', 'stupid', 'sucks']\n",
      "Rank 4: Value vec -> Layer 15, index 2454\n",
      "['fucking', 'bullshit', 'stupid', 'shit', 'crap', 'piss', 'disgust', 'ridiculous', 'fucked', 'fuck']\n",
      "Rank 5: Value vec -> Layer 1, index 9939\n",
      "['atti', 'stein', 'adu', 'ю', 'ess', 'iele', 'blur', 'auge', 'erg', 'им']\n",
      "Rank 6: Value vec -> Layer 13, index 13888\n",
      "['Wind', 'Mal', 'esh', 'Sto', 'ulo', 'Mono', 'Lower', 'moy', 'winds', 'nomin']\n",
      "Rank 7: Value vec -> Layer 3, index 11985\n",
      "['NU', 'ower', 'iaz', 'heck', 'aggi', 'ust', 'abstract', 'arroll', 'essen', 'dm']\n",
      "Rank 8: Value vec -> Layer 22, index 5047\n",
      "['shit', '****', 'shit', '***', '**', 'fucking', 'Fuck', '******', '***', '**']\n",
      "Rank 9: Value vec -> Layer 11, index 3134\n",
      "['Holl', 'Jur', 'zek', 'shr', 'tempor', 'ells', 'mast', 'chnitt', 'quare', 'Required']\n",
      "Rank 10: Value vec -> Layer 4, index 1609\n",
      "['nonsense', 'empty', 'driv', 'Tut', 'refresh', 'virtual', 'waste', 'bid', '…', '!']\n",
      "Rank 11: Value vec -> Layer 22, index 3443\n",
      "['DER', 'ỳ', 'ionato', 'Excell', 'icz', 'ERNAL', 'hythm', 'ocz', 'irtual', 'igd']\n",
      "Rank 12: Value vec -> Layer 25, index 3529\n",
      "['ne', 'Ne', 'Ne', 'neo', 'ne', 'né', 'Neil', 'Не', 'white', 'neur']\n",
      "Rank 13: Value vec -> Layer 10, index 10581\n",
      "['sources', 'sources', 'source', 'ņ', 'éra', 'Sources', 'Mot', 'zd', 'spr', 'Source']\n",
      "Rank 14: Value vec -> Layer 27, index 15268\n",
      "['ня', 'ля', 'я', 'ча', 'жа', 'nia', 'ря', 'ша', 'ja', 'тя']\n",
      "Rank 15: Value vec -> Layer 4, index 7710\n",
      "['inition', 'capacity', 'oko', 'ivas', 'urance', 'orney', 'ERCHANT', 'uß', 'yside', 'proceed']\n",
      "Rank 16: Value vec -> Layer 23, index 6313\n",
      "['web', 'web', 'Web', 'Web', 'webs', 'graphic', 'webpack', 'Website', 'Graph', 'website']\n",
      "Rank 17: Value vec -> Layer 20, index 1349\n",
      "['ass', 'fool', 'ASS', 'ass', 'idiot', 'ASS', 'Ass', 'complete', 'hole', 'Ass']\n",
      "Rank 18: Value vec -> Layer 0, index 14580\n",
      "['entr', 'aye', 'ój', 'ioc', '病', 'tainment', 'Sach', '�', 'NC', 'osto']\n",
      "Rank 19: Value vec -> Layer 18, index 5446\n",
      "['/******/', 'Gon', 'gon', 'cultiv', 'Rodr', 'Wil', 'Gar', 'Cameron', 'pur', 'dull']\n",
      "Rank 20: Value vec -> Layer 2, index 582\n",
      "['illet', 'sle', 'criptor', 'alph', 'thon', 'Louise', 'Pict', 'intellect', 'RC', 'ategory']\n",
      "Rank 21: Value vec -> Layer 5, index 15106\n",
      "['aris', 'inois', 'zas', 'isz', 'themselves', 'scal', 's', 'ars', '₁', 'ascript']\n",
      "Rank 22: Value vec -> Layer 2, index 8522\n",
      "['bras', 'ijk', 'bara', 'IMIT', 'memor', 'ан', 'elsewhere', 'snd', 'dedic', 'feld']\n",
      "Rank 23: Value vec -> Layer 27, index 5067\n",
      "['off', 'ass', 'off', 'ASS', 'ingen', 'ons', 'ija', 'Off', 'oko', 'offs']\n",
      "Rank 24: Value vec -> Layer 27, index 1424\n",
      "['Co', 'Jew', 'Wood', 'Cl', 'Flor', 'Crown', 'Mark', 'Br', 'Clay', 'Curt']\n",
      "Rank 25: Value vec -> Layer 26, index 10193\n",
      "['web', 'web', 'Web', 'Web', 'webs', 'webpack', 'WE', '網', 'EB', 'internet']\n",
      "Rank 26: Value vec -> Layer 1, index 5845\n",
      "['achuset', '�', 'worn', 'wo', 'oard', 'Eins', 'moder', 'aye', 'äst', 'ARK']\n",
      "Rank 27: Value vec -> Layer 15, index 2086\n",
      "['getElementById', 'rale', 'glow', 'EO', 'reen', 'Mach', 'ect', 'jos', 'emu', 'mach']\n",
      "Rank 28: Value vec -> Layer 12, index 9435\n",
      "['elij', 'lte', 'mv', 'Rein', 'gra', 'izi', 'adesh', 'msm', 'ken', 'Station']\n",
      "Rank 29: Value vec -> Layer 27, index 7944\n",
      "['elf', 'touch', 'ioso', 'touch', 'gorith', 'ugno', 'Touch', 'iot', 'ios', 'quet']\n",
      "Rank 30: Value vec -> Layer 26, index 3061\n",
      "['mor', 'env', 'env', 'vag', 'imply', 'appearing', 'mont', 'associations', 'iles', 'respectively']\n",
      "Rank 31: Value vec -> Layer 20, index 1120\n",
      "['adu', 'resid', 'sec', 'Mam', 'ExecutionContext', 'aggi', 'oton', 'seg', 'Lad', 'intim']\n",
      "Rank 32: Value vec -> Layer 5, index 12741\n",
      "['tou', 'pun', 'för', 'synchronized', 'SG', 'alia', 'Images', 'zoom', 'Labels', 'vb']\n",
      "Rank 33: Value vec -> Layer 13, index 6053\n",
      "['aude', 'Tol', 'aw', 'caused', 'ASS', 'awi', 'auf', 'ond', 'MAGES', 'climb']\n",
      "Rank 34: Value vec -> Layer 14, index 11281\n",
      "['sexual', 'sex', 'sex', 'girls', 'women', 'Sex', 'dating', 'dating', 'porn', 'sexy']\n",
      "Rank 35: Value vec -> Layer 22, index 12672\n",
      "['Mer', 'Mer', 'Lem', 'Way', 'Merge', 'Will', 'Ralph', 'omer', 'lio', 'mer']\n",
      "Rank 36: Value vec -> Layer 23, index 131\n",
      "['if', 'if', 'IF', 'IF', 'If', 'If', 'wenn', 'ifs', '如', 'ife']\n",
      "Rank 37: Value vec -> Layer 8, index 2789\n",
      "['bler', 'inder', 'itel', 'Hugo', 'azi', 'itzer', 'puzzle', 'XY', 'gravity', 'filer']\n",
      "Rank 38: Value vec -> Layer 2, index 13027\n",
      "['ån', 'dern', 'plaat', 'руко', 'Lis', 'eken', 'etto', 'Norway', 'Fernando', 'gon']\n",
      "Rank 39: Value vec -> Layer 17, index 3883\n",
      "['anto', 'ester', 'oda', 'idal', 'Aires', 'ools', 'ville', 'atos', 'inta', 'CH']\n",
      "Rank 40: Value vec -> Layer 21, index 4730\n",
      "['grain', 'Rice', 'rice', 'osto', 'eken', 'rice', 'bare', 'ionato', 'odox', 'Spot']\n",
      "Rank 41: Value vec -> Layer 4, index 13678\n",
      "['inode', 'hall', 'Pow', 'rä', 'hall', 'land', 'uen', 'hollow', 'ilis', 'plaat']\n",
      "Rank 42: Value vec -> Layer 18, index 6743\n",
      "['rede', 'units', 'units', 'unit', 'unit', 'izo', 'Unit', 'fund', 'share', 'share']\n",
      "Rank 43: Value vec -> Layer 19, index 9245\n",
      "['behind', 'Behind', 'backend', 'backend', 'rear', 'bg', 'bg', 'Backend', '背', 'hind']\n",
      "Rank 44: Value vec -> Layer 23, index 3668\n",
      "['association', 'associate', 'associations', 'Associ', 'associ', 'associ', 'Associ', 'Association', 'associated', 'affili']\n",
      "Rank 45: Value vec -> Layer 19, index 4689\n",
      "['crap', 'shit', 'damn', 'shit', 'damned', 'hell', 'bitch', 'piss', 'Hell', 'fuck']\n",
      "Rank 46: Value vec -> Layer 27, index 5053\n",
      "['inton', 'ng', 'mid', 'erm', 'saf', 'erst', 'pa', 'child', 'lon', 'ele']\n",
      "Rank 47: Value vec -> Layer 10, index 6660\n",
      "['掉', 'yet', 'aise', 'utch', '息', 'Yet', 'ura', 'ASS', '止', 'limits']\n",
      "Rank 48: Value vec -> Layer 6, index 7364\n",
      "['lie', 'fuck', 'da', 'Fuck', 'foul', 'bitch', 'crap', 'lie', 'nuts', 'tolerance']\n",
      "Rank 49: Value vec -> Layer 16, index 4861\n",
      "['uple', 'addy', 'ณ', 'dsi', 'дан', 'asant', 'inth', 'gepublice', 'agh', 'mma']\n",
      "Rank 50: Value vec -> Layer 1, index 13026\n",
      "['atin', 'uper', 'cke', 'naked', 'alter', 'tocol', 'Daddy', 'exh', 'NF', '倍']\n"
     ]
    }
   ],
   "source": [
    "# Value vectors similar to probe\n",
    "k = 50\n",
    "norm = model.model.norm  \n",
    "\n",
    "dot_prods = torch.einsum(\"nd,d->n\", norm(value_vectors), toxic_probe)\n",
    "top_value_vecs = dot_prods.topk(k).indices\n",
    "top_scores = dot_prods[top_value_vecs]\n",
    "\n",
    "for rank, vec_idx in enumerate(top_value_vecs):\n",
    "    layer = vec_idx.item() // (4096*4)\n",
    "    index = vec_idx.item() % (4096*4)\n",
    "    \n",
    "    print(f\"Rank {rank + 1}: Value vec -> Layer {layer}, index {index}\")\n",
    "    print(unembed_to_text(value_vectors[vec_idx], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "070f31f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shit', 'shit', 'fuck', 'Fuck', 'fucking', 'fucked', 'assh', 'asshole', 'upid', 'bullshit']\n"
     ]
    }
   ],
   "source": [
    "print(unembed_to_text(toxic_probe, model, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
